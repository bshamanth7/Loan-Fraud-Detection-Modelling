{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Extend cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Work/Gre/UTD/Courses/Fall/MIS6341/Softwares/Python/ml-fall-2023/Project2/SBA_loans_project_2.csv\")\n",
    "df.drop(columns=\"index\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>10003</td>\n",
       "      <td>JPMORGAN CHASE BANK NATL ASSOC</td>\n",
       "      <td>IL</td>\n",
       "      <td>561439</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAWTUCKET</td>\n",
       "      <td>RI</td>\n",
       "      <td>2860</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>541810</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISSAQUAH</td>\n",
       "      <td>WA</td>\n",
       "      <td>98027</td>\n",
       "      <td>FIRST-CITIZENS BK &amp; TR CO</td>\n",
       "      <td>WA</td>\n",
       "      <td>448210</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HURST</td>\n",
       "      <td>TX</td>\n",
       "      <td>76053</td>\n",
       "      <td>WILSHIRE BANK</td>\n",
       "      <td>CA</td>\n",
       "      <td>722213</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALPINE</td>\n",
       "      <td>CA</td>\n",
       "      <td>91901</td>\n",
       "      <td>CALIFORNIA BANK &amp; TRUST</td>\n",
       "      <td>CA</td>\n",
       "      <td>233210</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>Kenmore</td>\n",
       "      <td>NY</td>\n",
       "      <td>14217</td>\n",
       "      <td>KEYBANK NATIONAL ASSOCIATION</td>\n",
       "      <td>OH</td>\n",
       "      <td>561720</td>\n",
       "      <td>112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>22750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>MENOMONEE FALLS</td>\n",
       "      <td>WI</td>\n",
       "      <td>53051</td>\n",
       "      <td>WAUKESHA STATE BANK</td>\n",
       "      <td>WI</td>\n",
       "      <td>337110</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>412500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>LONGVIEW</td>\n",
       "      <td>TX</td>\n",
       "      <td>75604</td>\n",
       "      <td>CAPITAL ONE NATL ASSOC</td>\n",
       "      <td>VA</td>\n",
       "      <td>517310</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>128800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>114750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>CAMDEN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>8105</td>\n",
       "      <td>BANK OF AMERICA NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>447110</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>COVENTRY</td>\n",
       "      <td>RI</td>\n",
       "      <td>2816</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>541511</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   City State    Zip                            Bank  \\\n",
       "0              NEW YORK    NY  10003  JPMORGAN CHASE BANK NATL ASSOC   \n",
       "1             PAWTUCKET    RI   2860        CITIZENS BANK NATL ASSOC   \n",
       "2              ISSAQUAH    WA  98027       FIRST-CITIZENS BK & TR CO   \n",
       "3                 HURST    TX  76053                   WILSHIRE BANK   \n",
       "4                ALPINE    CA  91901         CALIFORNIA BANK & TRUST   \n",
       "...                 ...   ...    ...                             ...   \n",
       "800250          Kenmore    NY  14217    KEYBANK NATIONAL ASSOCIATION   \n",
       "800251  MENOMONEE FALLS    WI  53051             WAUKESHA STATE BANK   \n",
       "800252         LONGVIEW    TX  75604          CAPITAL ONE NATL ASSOC   \n",
       "800253           CAMDEN    NJ   8105      BANK OF AMERICA NATL ASSOC   \n",
       "800254         COVENTRY    RI   2816        CITIZENS BANK NATL ASSOC   \n",
       "\n",
       "       BankState   NAICS  NoEmp  NewExist  CreateJob  RetainedJob  \\\n",
       "0             IL  561439      9       1.0          1            9   \n",
       "1             RI  541810      8       1.0          4           12   \n",
       "2             WA  448210      9       2.0          0            0   \n",
       "3             CA  722213      4       1.0          0            4   \n",
       "4             CA  233210      1       1.0          0            1   \n",
       "...          ...     ...    ...       ...        ...          ...   \n",
       "800250        OH  561720    112       1.0          0            0   \n",
       "800251        WI  337110     75       1.0          0           75   \n",
       "800252        VA  517310      2       1.0          0            0   \n",
       "800253        RI  447110      4       2.0          0            0   \n",
       "800254        RI  541511      1       1.0          0            1   \n",
       "\n",
       "        FranchiseCode  UrbanRural RevLineCr LowDoc  DisbursementGross  \\\n",
       "0                   1           1         0      N            68000.0   \n",
       "1                   0           1         N      N            90000.0   \n",
       "2                   1           0         N      N           450000.0   \n",
       "3                   1           1         0      N           140000.0   \n",
       "4                   1           2         Y      N            50000.0   \n",
       "...               ...         ...       ...    ...                ...   \n",
       "800250              1           1         N      N            45500.0   \n",
       "800251              1           1         0      N           550000.0   \n",
       "800252              1           1         0      Y           128800.0   \n",
       "800253              1           1         Y      N           100000.0   \n",
       "800254              0           1         N      N            10000.0   \n",
       "\n",
       "        BalanceGross    GrAppv  SBA_Appv  MIS_Status  \n",
       "0                0.0   68000.0   34000.0           0  \n",
       "1                0.0   90000.0   45000.0           1  \n",
       "2                0.0  450000.0  337500.0           0  \n",
       "3                0.0  165000.0   82500.0           0  \n",
       "4                0.0   50000.0   25000.0           0  \n",
       "...              ...       ...       ...         ...  \n",
       "800250           0.0   45500.0   22750.0           0  \n",
       "800251           0.0  550000.0  412500.0           0  \n",
       "800252           0.0  135000.0  114750.0           0  \n",
       "800253           0.0  100000.0   50000.0           0  \n",
       "800254           0.0   10000.0    5000.0           0  \n",
       "\n",
       "[800255 rows x 19 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                   26\n",
       "State                  13\n",
       "Zip                     0\n",
       "Bank                 1381\n",
       "BankState            1386\n",
       "NAICS                   0\n",
       "NoEmp                   0\n",
       "NewExist              127\n",
       "CreateJob               0\n",
       "RetainedJob             0\n",
       "FranchiseCode           0\n",
       "UrbanRural              0\n",
       "RevLineCr            4016\n",
       "LowDoc               2316\n",
       "DisbursementGross       0\n",
       "BalanceGross            0\n",
       "GrAppv                  0\n",
       "SBA_Appv                0\n",
       "MIS_Status              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City unique values are ['NEW YORK' 'PAWTUCKET' 'ISSAQUAH' ... 'ST  FRANCIS' 'Stevens point'\n",
      " 'Pylesville']\n",
      "\n",
      "\n",
      "City data type is object\n",
      "State unique values are ['NY' 'RI' 'WA' 'TX' 'CA' 'NC' 'MN' 'MO' 'FL' 'IA' 'IL' 'DC' 'PA' 'AL'\n",
      " 'MS' 'OH' 'MA' 'NJ' 'ME' 'NV' 'LA' 'MI' 'IN' 'GA' 'UT' 'VA' 'WI' 'TN'\n",
      " 'KS' 'NH' 'CO' 'CT' 'KY' 'AZ' 'ID' 'DE' 'SD' 'AR' 'MD' 'OK' 'SC' 'NM'\n",
      " 'MT' 'NE' 'OR' 'WY' 'AK' 'HI' 'VT' 'ND' 'WV' nan]\n",
      "\n",
      "\n",
      "State data type is object\n",
      "Zip unique values are [10003  2860 98027 ... 78944 17814 95812]\n",
      "\n",
      "\n",
      "Zip data type is int64\n",
      "Bank unique values are ['JPMORGAN CHASE BANK NATL ASSOC' 'CITIZENS BANK NATL ASSOC'\n",
      " 'FIRST-CITIZENS BK & TR CO' ... 'TULSA NATIONAL BANCSHARES, INC'\n",
      " 'BEACH PLAZA LLC' 'THE LEADERS BANK']\n",
      "\n",
      "\n",
      "Bank data type is object\n",
      "BankState unique values are ['IL' 'RI' 'WA' 'CA' 'NC' 'MN' 'MO' 'OR' 'FL' 'IA' 'SD' 'DC' 'TX' 'PA'\n",
      " 'VA' 'AL' 'OH' 'MS' 'IN' 'MA' 'ME' 'MI' 'DE' 'UT' 'SC' 'NY' 'KS' 'CO'\n",
      " 'LA' 'WI' 'CT' 'AZ' 'AR' 'MD' 'OK' 'NM' 'ID' 'MT' 'NJ' 'KY' 'NE' 'WY'\n",
      " 'GA' 'HI' 'NH' 'VT' 'ND' 'TN' nan 'NV' 'AK' 'WV' 'PR' 'EN' 'GU']\n",
      "\n",
      "\n",
      "BankState data type is object\n",
      "NAICS unique values are [561439 541810 448210 ... 922140 221114 333241]\n",
      "\n",
      "\n",
      "NAICS data type is int64\n",
      "NoEmp unique values are [   9    8    4    1    3   25   10    2   12    6   21   15   19    7\n",
      "   70   45   14   57   30   16   13   35    5   17   11   42   33   36\n",
      "    0   65   20   23  175   18   50   34   60   26   80   40   22   24\n",
      "   31  300   55   29   44   76 3030   75   32   28   41  135   52  100\n",
      "   90   51   37  350   46  207   27   64  160   98   92  190   38   47\n",
      "   39   62   85  985  150   48   79   72  387   84   69 9945   49   68\n",
      "  124   43   73  200  140   59  120  174   54   71  101  102   56 5000\n",
      "  142   67  195  185   53  145  435  110  109  115  425  281   58  153\n",
      "   95   63   61  750  133   81   74   83   82  700  111  132  114   93\n",
      "   78  146   89   77  170  250  205  125  130  184   94  105   97   99\n",
      "   86  104  158  220  155  163  247  246  137  106  450  113  151   96\n",
      "  500  116 1000  118  280  141 5149   66  126   88  400  188  108  154\n",
      "  223  325  900  127  189  222  360   91  107  498  131   87  230  421\n",
      "  162  218  515  180  271  138  128  122  386  179  345  129  165  240\n",
      "  117 3400 1644  315  182  134  123  112  275  139  210  232  260  288\n",
      " 6000  245  119  215 1150  600  258  227  261  206  257 1382  270  203\n",
      "  256  499  144  285  161  295 1400  375  608 1010 1500  177 1200  103\n",
      "  173 4000  121 1700  314  340  192  307  147  329  339 1451 8041  226\n",
      " 1003  225  231  254  148  344  191  712  967  149  187  403  152  520\n",
      " 2202  420  299  351 1524  212  136  156  166 7231  323 5921  208  290\n",
      "  202 7538 5812  143  197  213  550  310  305 3900 1112  233  761  241\n",
      "  521  228 3200 2200  317  249 2000  346  243  178  840  167  475  172\n",
      "  248 3000 1515 1800  330  237 1461  214  625  740  186  211 2151  204\n",
      "  255  217 2400 5680  196 1005 7389  306  171 5211  265  168  157  327\n",
      " 1100  427  390 2401  394  236 3100  216  289  458  850  176 1600 8000\n",
      "  169  221  720 2501  760  430  384 1981  253 2725  234  277  510  194\n",
      "  224  263  463  259 9090 3737  268  365  488  283  278  342  332  404\n",
      "  484  423  198 1940  318 3713  530  235  433  273  353 4100  455  304\n",
      "  382  276  267  424  193  640  606  456 3089  164  407  336  362 1706\n",
      "  585  560  252  355  576 4685  308  251  320  396 7212  442  380 3500\n",
      "  385  808 1300  183  376 4005  605  454  312  209  505 9999 1233 1711\n",
      "  181 5947  523  479 7000  279  301  262 3334  358 2300 2100  448  602\n",
      "  713 7941  413  780 4012  635  302 2020  685 2120  575  294  540  238\n",
      "  369  405  313 2510 1900 5555 1020  395 4847  377  525  445 2610  401\n",
      "  354  322 7241 2500 5013  287 3009  242  266  465  688 2700 4658 1073\n",
      " 1340  717  410  229  269 5200  282 9992 1520 1235  274  480  485 1980\n",
      " 1050  296  383  426  408 1920 6501 7216  544  298  368  782  476  324\n",
      " 1629 1550  609  363  680 1542  827 7111  357 1012 2232  800 1101  464\n",
      "  447  735  284 2010  341 5084  828  495  370  538  319 7991 1603 7999\n",
      " 3732 8018 2121  199  535  244 1250 1280 9000  292 1145  293 2520  650\n",
      "  356  159 1030 4800 7007  328 4300 3170  570  660  414  441  429  823\n",
      "  367  348  858]\n",
      "\n",
      "\n",
      "NoEmp data type is int64\n",
      "NewExist unique values are [ 1.  2.  0. nan]\n",
      "\n",
      "\n",
      "NewExist data type is float64\n",
      "CreateJob unique values are [   1    4    0   15    3    6    8    9    2   20    7   10   12    5\n",
      "   26   35   30   13   23   11   45   40   65   29   25   16   46   21\n",
      "  458   14   73   70 8800   43  120   38   28   22   49   41   59   33\n",
      "   80   19   17   48   60   50  250   24   18  150   37   57  100   31\n",
      "   44   39   32   79   96   89  118   27   75  451   71  450   85   42\n",
      "   36  456   52  105  135  125  452  200  300   54   63   61   90   34\n",
      "  154   64   47   76   82  171   56  175  256   55  198   58  110  138\n",
      " 3000  264   98  158   69   95  162   68  124   66  119  860   72   92\n",
      "  115   83  168  206   78  116   62  500   53   67   84  255  600   51\n",
      "  400  137  104  130  152  140  454  226   77  453  225   97  270  123\n",
      "  126 3100  240  108  160  102 1530  235   99  189  114   87  106  165\n",
      "  112  179  101   88  141  167  183  131   81  455   94  433  205  136\n",
      " 1618 1100  223  146  457 5199 1000   74 3500  121  409  750  220 1711\n",
      " 5085  148  155  184 1027 2515  186  280 5621 1016  145  310  129  360\n",
      "  386   86  375  169  109  170   93  182  397  195  365  180  128  190\n",
      " 1011  221  103  350  157  174  222  127  149 1150  480  363 2140  214\n",
      "  252  569 2020  320  144  164  153 1118  139  151  163  210]\n",
      "\n",
      "\n",
      "CreateJob data type is int64\n",
      "RetainedJob unique values are [   9   12    0    4    1   40   10    2    6    8    5   20   30   13\n",
      "   35   11    3   14   19    7   34   21   23   18   50   22   85   80\n",
      "   60   45   15  330   25   65   33   29   17   16   44   32   31   28\n",
      "   41   27   90   24  207  160   92  190   38   46 8800   26   48   72\n",
      "   84   36   70  200  140  120   54   52   71   53   47  102   55   75\n",
      "  150  142   37   43   64  300  117   42   95   39  281   49   58   96\n",
      "  212  100   63   79   82   57  111   69   62  135  250   61   56  155\n",
      "   78  104  158   67  163  270  350  151  500  116   51  118  275  141\n",
      "  450  126   74   86  223  387   76  498  189   87  130  115   59  145\n",
      "  205  175  125  256  138  105   93  137  164  180  219  139   77  110\n",
      "   68   81  103  210  109  167  230   83   99  162  185  171   91   97\n",
      "  119  304  101   98  107  285  240  257  170   73  165  229  161  149\n",
      "  173  750  113  231  114  168  156  362  967   88  128  122  127   89\n",
      "  220  129  251  404  375   66  203  550  267  177  133  123  263  143\n",
      "   94 3900  182  121 1300  384 2200  254  900  243  112  178  310  226\n",
      "  184  237  515  146  154  192  265  157  327  245  108  400  194  172\n",
      "  169  134  186  153  216  106  152 4441  360  124  259  187  131  202\n",
      "  316  600  472  371  278  342  206  214  484  204  390  318  225 3225\n",
      "  286 1700  428  176  147  497  268  585  312  393  148  280  290  475\n",
      "  235  291  320  369  132 1711  197  523  195  144  448  602  217 3100\n",
      "  302  136  685  540  295  215  366  322  287  315  485  266  610  292\n",
      "  476  208  430  410  247  191 1600  420  325 4000  233  188 5000  355\n",
      "  196  260  274  480  544  298  262  609  363  199  815  277  403  166\n",
      " 7250  720  370  548 3200  911  183  221 1500 1000  675  535  232  236\n",
      "  198  159  255  252  356  394 1111  201 9500  328  297  660  700  317]\n",
      "\n",
      "\n",
      "RetainedJob data type is int64\n",
      "FranchiseCode unique values are [    1     0 78760 ... 21424 41418 29580]\n",
      "\n",
      "\n",
      "FranchiseCode data type is int64\n",
      "UrbanRural unique values are [1 0 2]\n",
      "\n",
      "\n",
      "UrbanRural data type is int64\n",
      "RevLineCr unique values are ['0' 'N' 'Y' 'T' nan '1' 'A' '`' '4' 'R' '2' '.' '5' 'C' ',' '-' 'Q' '7'\n",
      " '3']\n",
      "\n",
      "\n",
      "RevLineCr data type is object\n",
      "LowDoc unique values are ['N' 'Y' '0' nan 'C' 'A' 'S' 'R' '1']\n",
      "\n",
      "\n",
      "LowDoc data type is object\n",
      "DisbursementGross unique values are [ 68000.  90000. 450000. ... 199123.  67516.  97203.]\n",
      "\n",
      "\n",
      "DisbursementGross data type is float64\n",
      "BalanceGross unique values are [0.00000e+00 4.15090e+04 3.95476e+05 9.11100e+03 8.46170e+04 8.27875e+05\n",
      " 1.27500e+04 9.96262e+05 9.69080e+04 2.50000e+04 1.15820e+05 1.76000e+03\n",
      " 3.71000e+04 6.00000e+02 4.31270e+04]\n",
      "\n",
      "\n",
      "BalanceGross data type is float64\n",
      "GrAppv unique values are [  68000.   90000.  450000. ... 1853900.   32916.   35224.]\n",
      "\n",
      "\n",
      "GrAppv data type is float64\n",
      "SBA_Appv unique values are [  34000.   45000.  337500. ...   26333. 1609000.   17612.]\n",
      "\n",
      "\n",
      "SBA_Appv data type is float64\n",
      "MIS_Status unique values are [0 1]\n",
      "\n",
      "\n",
      "MIS_Status data type is int64\n"
     ]
    }
   ],
   "source": [
    "#show unique values in each column and its data type\n",
    "for col in df.columns:\n",
    "    print(f'{col} unique values are {df[col].unique()}')\n",
    "    print(\"\\n\")\n",
    "    print(f'{col} data type is {df[col].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>10003</td>\n",
       "      <td>JPMORGAN CHASE BANK NATL ASSOC</td>\n",
       "      <td>IL</td>\n",
       "      <td>561439</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAWTUCKET</td>\n",
       "      <td>RI</td>\n",
       "      <td>2860</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>541810</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISSAQUAH</td>\n",
       "      <td>WA</td>\n",
       "      <td>98027</td>\n",
       "      <td>FIRST-CITIZENS BK &amp; TR CO</td>\n",
       "      <td>WA</td>\n",
       "      <td>448210</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HURST</td>\n",
       "      <td>TX</td>\n",
       "      <td>76053</td>\n",
       "      <td>WILSHIRE BANK</td>\n",
       "      <td>CA</td>\n",
       "      <td>722213</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALPINE</td>\n",
       "      <td>CA</td>\n",
       "      <td>91901</td>\n",
       "      <td>CALIFORNIA BANK &amp; TRUST</td>\n",
       "      <td>CA</td>\n",
       "      <td>233210</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>Kenmore</td>\n",
       "      <td>NY</td>\n",
       "      <td>14217</td>\n",
       "      <td>KEYBANK NATIONAL ASSOCIATION</td>\n",
       "      <td>OH</td>\n",
       "      <td>561720</td>\n",
       "      <td>112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>22750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>MENOMONEE FALLS</td>\n",
       "      <td>WI</td>\n",
       "      <td>53051</td>\n",
       "      <td>WAUKESHA STATE BANK</td>\n",
       "      <td>WI</td>\n",
       "      <td>337110</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>412500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>LONGVIEW</td>\n",
       "      <td>TX</td>\n",
       "      <td>75604</td>\n",
       "      <td>CAPITAL ONE NATL ASSOC</td>\n",
       "      <td>VA</td>\n",
       "      <td>517310</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>128800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>114750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>CAMDEN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>8105</td>\n",
       "      <td>BANK OF AMERICA NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>447110</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>COVENTRY</td>\n",
       "      <td>RI</td>\n",
       "      <td>2816</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>541511</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   City State    Zip                            Bank  \\\n",
       "0              NEW YORK    NY  10003  JPMORGAN CHASE BANK NATL ASSOC   \n",
       "1             PAWTUCKET    RI   2860        CITIZENS BANK NATL ASSOC   \n",
       "2              ISSAQUAH    WA  98027       FIRST-CITIZENS BK & TR CO   \n",
       "3                 HURST    TX  76053                   WILSHIRE BANK   \n",
       "4                ALPINE    CA  91901         CALIFORNIA BANK & TRUST   \n",
       "...                 ...   ...    ...                             ...   \n",
       "800250          Kenmore    NY  14217    KEYBANK NATIONAL ASSOCIATION   \n",
       "800251  MENOMONEE FALLS    WI  53051             WAUKESHA STATE BANK   \n",
       "800252         LONGVIEW    TX  75604          CAPITAL ONE NATL ASSOC   \n",
       "800253           CAMDEN    NJ   8105      BANK OF AMERICA NATL ASSOC   \n",
       "800254         COVENTRY    RI   2816        CITIZENS BANK NATL ASSOC   \n",
       "\n",
       "       BankState   NAICS  NoEmp  NewExist  CreateJob  RetainedJob  \\\n",
       "0             IL  561439      9       1.0          1            9   \n",
       "1             RI  541810      8       1.0          4           12   \n",
       "2             WA  448210      9       2.0          0            0   \n",
       "3             CA  722213      4       1.0          0            4   \n",
       "4             CA  233210      1       1.0          0            1   \n",
       "...          ...     ...    ...       ...        ...          ...   \n",
       "800250        OH  561720    112       1.0          0            0   \n",
       "800251        WI  337110     75       1.0          0           75   \n",
       "800252        VA  517310      2       1.0          0            0   \n",
       "800253        RI  447110      4       2.0          0            0   \n",
       "800254        RI  541511      1       1.0          0            1   \n",
       "\n",
       "        FranchiseCode  UrbanRural RevLineCr LowDoc  DisbursementGross  \\\n",
       "0                   1           1         0      N            68000.0   \n",
       "1                   0           1         N      N            90000.0   \n",
       "2                   1           0         N      N           450000.0   \n",
       "3                   1           1         0      N           140000.0   \n",
       "4                   1           2         Y      N            50000.0   \n",
       "...               ...         ...       ...    ...                ...   \n",
       "800250              1           1         N      N            45500.0   \n",
       "800251              1           1         0      N           550000.0   \n",
       "800252              1           1         0      Y           128800.0   \n",
       "800253              1           1         Y      N           100000.0   \n",
       "800254              0           1         N      N            10000.0   \n",
       "\n",
       "        BalanceGross    GrAppv  SBA_Appv  MIS_Status  \n",
       "0                0.0   68000.0   34000.0           0  \n",
       "1                0.0   90000.0   45000.0           1  \n",
       "2                0.0  450000.0  337500.0           0  \n",
       "3                0.0  165000.0   82500.0           0  \n",
       "4                0.0   50000.0   25000.0           0  \n",
       "...              ...       ...       ...         ...  \n",
       "800250           0.0   45500.0   22750.0           0  \n",
       "800251           0.0  550000.0  412500.0           0  \n",
       "800252           0.0  135000.0  114750.0           0  \n",
       "800253           0.0  100000.0   50000.0           0  \n",
       "800254           0.0   10000.0    5000.0           0  \n",
       "\n",
       "[800255 rows x 19 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevLineCr ['N' 'Y']\n",
      "LowDoc ['N' 'Y']\n",
      "NewExist [1.0 2.0 None]\n"
     ]
    }
   ],
   "source": [
    "for i in df['RevLineCr']:\n",
    "    if i not in ['Y','N']:\n",
    "        df['RevLineCr'].replace(i,'N',inplace=True)\n",
    "print(\"RevLineCr\",df['RevLineCr'].unique())\n",
    "\n",
    "for i in df['LowDoc']:\n",
    "    if i not in ['Y','N']:\n",
    "        df['LowDoc'].replace(i,'N',inplace=True)\n",
    "print(\"LowDoc\",df['LowDoc'].unique())\n",
    "\n",
    "for i in df['NewExist']:\n",
    "    if i not in [1,2]:\n",
    "        df['NewExist'].replace(i,None,inplace=True)\n",
    "print(\"NewExist\",df['NewExist'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                   26\n",
       "State                  13\n",
       "Zip                     0\n",
       "Bank                 1381\n",
       "BankState            1386\n",
       "NAICS                   0\n",
       "NoEmp                   0\n",
       "NewExist             1057\n",
       "CreateJob               0\n",
       "RetainedJob             0\n",
       "FranchiseCode           0\n",
       "UrbanRural              0\n",
       "RevLineCr               0\n",
       "LowDoc                  0\n",
       "DisbursementGross       0\n",
       "BalanceGross            0\n",
       "GrAppv                  0\n",
       "SBA_Appv                0\n",
       "MIS_Status              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols=['City', 'State', 'Bank', 'BankState', 'RevLineCr', 'LowDoc','NewExist']\n",
    "for column in category_cols:\n",
    "  df[column]=df[column].fillna(df[column].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                 0\n",
       "State                0\n",
       "Zip                  0\n",
       "Bank                 0\n",
       "BankState            0\n",
       "NAICS                0\n",
       "NoEmp                0\n",
       "NewExist             0\n",
       "CreateJob            0\n",
       "RetainedJob          0\n",
       "FranchiseCode        0\n",
       "UrbanRural           0\n",
       "RevLineCr            0\n",
       "LowDoc               0\n",
       "DisbursementGross    0\n",
       "BalanceGross         0\n",
       "GrAppv               0\n",
       "SBA_Appv             0\n",
       "MIS_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((560178, 19), (240077, 19))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test = train_test_split(df,test_size=0.3,random_state=123)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Training set has 560178 rows and testing set has 240077 samples\n",
    "\n",
    "Target encoding is a data preprocessing technique used to convert categorical variables into numerical values that can be used by machine learning algorithms. It works by replacing each category with the average value of the target variable for that category. This can be helpful for algorithms that cannot handle categorical variables directly.\n",
    "\n",
    "In this case the target variable is \"MIS_Status\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148172</th>\n",
       "      <td>0.215946</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>45648</td>\n",
       "      <td>0.740692</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>452990</td>\n",
       "      <td>2</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>10625.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744579</th>\n",
       "      <td>0.226933</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>43240</td>\n",
       "      <td>0.133135</td>\n",
       "      <td>0.158188</td>\n",
       "      <td>445310</td>\n",
       "      <td>7</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321200</th>\n",
       "      <td>0.252778</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>21037</td>\n",
       "      <td>0.194430</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74901</th>\n",
       "      <td>0.275938</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>90071</td>\n",
       "      <td>0.141177</td>\n",
       "      <td>0.178801</td>\n",
       "      <td>541310</td>\n",
       "      <td>12</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.251879</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>985500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426895</th>\n",
       "      <td>0.057056</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>95037</td>\n",
       "      <td>0.412096</td>\n",
       "      <td>0.380604</td>\n",
       "      <td>561720</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City     State    Zip      Bank  BankState   NAICS  NoEmp  \\\n",
       "148172  0.215946  0.165802  45648  0.740692   0.217642  452990      2   \n",
       "744579  0.226933  0.165802  43240  0.133135   0.158188  445310      7   \n",
       "321200  0.252778  0.196143  21037  0.194430   0.076619       0      3   \n",
       "74901   0.275938  0.184227  90071  0.141177   0.178801  541310     12   \n",
       "426895  0.057056  0.184227  95037  0.412096   0.380604  561720      1   \n",
       "\n",
       "        NewExist  CreateJob  RetainedJob  FranchiseCode  UrbanRural  \\\n",
       "148172   0.17067          2            2              0    0.186517   \n",
       "744579   0.17067          0            0              0    0.243731   \n",
       "321200   0.17067          0            0              1    0.070886   \n",
       "74901    0.17067         12           12              1    0.243731   \n",
       "426895   0.17067          0            1              0    0.243731   \n",
       "\n",
       "        RevLineCr    LowDoc  DisbursementGross  BalanceGross    GrAppv  \\\n",
       "148172   0.152625  0.186815            12500.0           0.0   12500.0   \n",
       "744579   0.152625  0.186815            20000.0           0.0   20000.0   \n",
       "321200   0.152625  0.089154            25000.0           0.0   25000.0   \n",
       "74901    0.251879  0.186815           985500.0           0.0  350000.0   \n",
       "426895   0.152625  0.186815            50000.0           0.0   50000.0   \n",
       "\n",
       "        SBA_Appv  MIS_Status  \n",
       "148172   10625.0           1  \n",
       "744579   10000.0           0  \n",
       "321200   20000.0           0  \n",
       "74901   175000.0           1  \n",
       "426895   25000.0           0  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target encoder\n",
    "import category_encoders as ce\n",
    "categorical_columns = ['City', 'State', 'Bank', 'BankState', 'RevLineCr', 'LowDoc','NewExist', 'UrbanRural']\n",
    "\n",
    "encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "encoder.fit(X_train, X_train['MIS_Status'])\n",
    "\n",
    "train_encoded = encoder.transform(X_train)\n",
    "test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Renaming the columns\n",
    "train_encoded.rename(columns={col: col + \"_trg\" if col in categorical_columns else col for col in train_encoded.columns}, inplace=False)\n",
    "test_encoded.rename(columns={col: col + \"_trg\" if col in categorical_columns else col for col in test_encoded.columns}, inplace=False)\n",
    "\n",
    "train_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler in scikit-learn is a preprocessing technique that centers and scales numerical features such that they have a mean of zero and a standard deviation of one.\n",
    "\n",
    "We will make use of the StandardScaler, which is used to transform both the training and test data in the same way, ensuring that the features have the same mean and standard deviation in both datasets.\n",
    "\n",
    "Here we will scale it on the training set and transform on both training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148172</th>\n",
       "      <td>0.215946</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>45648</td>\n",
       "      <td>0.740692</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>452990</td>\n",
       "      <td>-0.123748</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.026808</td>\n",
       "      <td>-0.036871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.654946</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.635102</td>\n",
       "      <td>-0.606817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744579</th>\n",
       "      <td>0.226933</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>43240</td>\n",
       "      <td>0.133135</td>\n",
       "      <td>0.158188</td>\n",
       "      <td>445310</td>\n",
       "      <td>-0.058247</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.628851</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.608622</td>\n",
       "      <td>-0.609553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321200</th>\n",
       "      <td>0.252778</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>21037</td>\n",
       "      <td>0.194430</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.110648</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>-0.611454</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.590969</td>\n",
       "      <td>-0.565780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74901</th>\n",
       "      <td>0.275938</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>90071</td>\n",
       "      <td>0.141177</td>\n",
       "      <td>0.178801</td>\n",
       "      <td>541310</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.251879</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>2.730474</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>0.556485</td>\n",
       "      <td>0.112702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426895</th>\n",
       "      <td>0.057056</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>95037</td>\n",
       "      <td>0.412096</td>\n",
       "      <td>0.380604</td>\n",
       "      <td>561720</td>\n",
       "      <td>-0.136849</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.041138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.524470</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.502703</td>\n",
       "      <td>-0.543894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City     State    Zip      Bank  BankState   NAICS     NoEmp  \\\n",
       "148172  0.215946  0.165802  45648  0.740692   0.217642  452990 -0.123748   \n",
       "744579  0.226933  0.165802  43240  0.133135   0.158188  445310 -0.058247   \n",
       "321200  0.252778  0.196143  21037  0.194430   0.076619       0 -0.110648   \n",
       "74901   0.275938  0.184227  90071  0.141177   0.178801  541310  0.007255   \n",
       "426895  0.057056  0.184227  95037  0.412096   0.380604  561720 -0.136849   \n",
       "\n",
       "        NewExist  CreateJob  RetainedJob  FranchiseCode  UrbanRural  \\\n",
       "148172   0.17067  -0.026808    -0.036871              0    0.186517   \n",
       "744579   0.17067  -0.035352    -0.045405              0    0.243731   \n",
       "321200   0.17067  -0.035352    -0.045405              1    0.070886   \n",
       "74901    0.17067   0.015917     0.005801              1    0.243731   \n",
       "426895   0.17067  -0.035352    -0.041138              0    0.243731   \n",
       "\n",
       "        RevLineCr    LowDoc  DisbursementGross  BalanceGross    GrAppv  \\\n",
       "148172   0.152625  0.186815          -0.654946     -0.002095 -0.635102   \n",
       "744579   0.152625  0.186815          -0.628851     -0.002095 -0.608622   \n",
       "321200   0.152625  0.089154          -0.611454     -0.002095 -0.590969   \n",
       "74901    0.251879  0.186815           2.730474     -0.002095  0.556485   \n",
       "426895   0.152625  0.186815          -0.524470     -0.002095 -0.502703   \n",
       "\n",
       "        SBA_Appv  MIS_Status  \n",
       "148172 -0.606817           1  \n",
       "744579 -0.609553           0  \n",
       "321200 -0.565780           0  \n",
       "74901   0.112702           1  \n",
       "426895 -0.543894           0  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from copy import deepcopy\n",
    "\n",
    "numerical_columns = [ 'NoEmp', 'CreateJob', 'RetainedJob', 'GrAppv', 'SBA_Appv', 'DisbursementGross', 'BalanceGross']\n",
    "scaler = StandardScaler()\n",
    "train_encoded[numerical_columns] = scaler.fit_transform(train_encoded[numerical_columns])\n",
    "test_encoded[numerical_columns] = scaler.transform(test_encoded[numerical_columns])\n",
    "\n",
    "train_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created Feature extraction by making use of old variables in the following way\n",
    "\n",
    "\n",
    "(1) Log_Disbursement which gives the natural logarithmic form of DisbursementGross variable\n",
    "\n",
    "(2) Log_GrAppv the logarithmic version of the approved loan amount by the bank\n",
    "\n",
    "(3) Log_SBA_Appv, the logarithmic amount of the approved loan that will be assisted by SBA \n",
    "\n",
    "(4) Log_BalanceGross, is the logarithmic amount of total amount in an account or the total value of a financial asset or liability before any deductions or adjustments are made.\n",
    "\n",
    "(5) TotalJobs variable which is an addition of Createjobs(New people recruited) and RetainedJob (workers working before)\n",
    "\n",
    "(6) IncomeToLoan its values are calculated by dividing the 'DisbursementGross' column by the 'SBA_Appv' column for each corresponding row. This ratio can help you analyze the relationship between the amount disbursed and the approved SBA loan amount in terms of income.\n",
    "\n",
    "(7)  EmployeesToLoanRatio, its values are calculated by dividing the 'NoEmp' column (number of employees) by the 'SBA_Appv' column (approved SBA loan amount) for each corresponding row. This ratio can help you analyze the relationship between the number of employees and the size of the SBA loan approved for each entry in the dataset.\n",
    "\n",
    "(8) JobPerLoan, its values are calculated by dividing the 'TotalJobs' column (representing the total number of jobs) by the 'SBA_Appv' column (approved SBA loan amount) for each corresponding row. This ratio can help you analyze the impact of the SBA loan on job creation or support, expressed as the number of jobs per unit of loan amount approved.\n",
    "\n",
    "(9) Gauren_SBA_Appv, Its values are calculated by dividing the 'GrAppv' column (gross amount approved by the lender) by the 'SBA_Appv' column (the approved SBA loan amount) for each corresponding row. This ratio helps you analyze the extent to which the SBA is guaranteeing the loan relative to the total loan amount approved by the lender.\n",
    "\n",
    "(10) DefaultRate, Finally, we create a new feature 'DefaultRate' in the 'train_encoded' DataFrame and set its value to the calculated default rate for the particular group of loans based on the \"MIS_Status\" variable. This feature will represent the percentage of loans in the group that are classified as defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Features\n",
    "import numpy as np\n",
    "# Apply the log transformation to the specific feature in your training data\n",
    "#small_constant = 1e-10  # You can adjust this constant as needed\n",
    "# df['LogColumn'] = np.log(df['OriginalColumn'] + small_constant)\n",
    "train_encoded['Log_DisbursementGross'] = np.log1p(train_encoded['DisbursementGross'])\n",
    "train_encoded['Log_GrAppv'] = np.log1p(train_encoded['GrAppv'])\n",
    "train_encoded['Log_SBA_Appv'] = np.log1p(train_encoded['SBA_Appv'])\n",
    "train_encoded['Log_BalanceGross'] = np.log1p(train_encoded['BalanceGross'])\n",
    "train_encoded['TotalJobs'] = train_encoded['CreateJob'] + train_encoded['RetainedJob']\n",
    "#train_encoded['Loan_Efficiency'] = train_encoded['DisbursementGross'] / (train_encoded['CreateJob'] + train_encoded['RetainedJob'] + 1)\n",
    "# Calculate 'LoanToIncomeRatio' as a ratio of 'SBA_Appv' to 'DisbursementGross'\n",
    "train_encoded['IncomeToLoanRatio'] = train_encoded['DisbursementGross'] / train_encoded['SBA_Appv']\n",
    "# Calculate 'LoanToEmployeesRatio' as a ratio of 'SBA_Appv' to 'NoEmp'\n",
    "train_encoded['EmployeesToLoanRatio'] = train_encoded['NoEmp'] / train_encoded['SBA_Appv']\n",
    "# Create a binary feature to indicate loans with a balance ('BalanceGross' > 0)\n",
    "#train_encoded['HasBalance'] = (train_encoded['BalanceGross'] > 0).astype(int)\n",
    "# Calculate 'LoanPerJob' as a ratio of 'SBA_Appv' to 'TotalJobs'\n",
    "train_encoded['JobPerLoan'] = train_encoded['TotalJobs'] / train_encoded['SBA_Appv'] \n",
    "# Calculate SBA's Gaurenteed Portion of Approved Loan\n",
    "train_encoded['Gauren_SBA_Appv'] = train_encoded['GrAppv'] / train_encoded['SBA_Appv']\n",
    "# Filter the DataFrame to include only the relevant rows\n",
    "default_group = train_encoded[train_encoded['MIS_Status'].isin([0, 1])]\n",
    "# Calculate the total number of loans in the filtered group\n",
    "total_loans = len(default_group)\n",
    "# Calculate the number of defaults (CHGOFF) in the filtered group\n",
    "default_loans = len(default_group[default_group['MIS_Status'] == 1])\n",
    "# Calculate the default rate as a percentage\n",
    "default_rate = (default_loans / total_loans) * 100\n",
    "# Create a new feature 'DefaultRate' with the calculated default rate\n",
    "train_encoded['DefaultRate'] = default_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Features\n",
    "import numpy as np\n",
    "# Apply the log transformation to the specific feature in your training data\n",
    "#small_constant = 1e-10  # You can adjust this constant as needed\n",
    "# df['LogColumn'] = np.log(df['OriginalColumn'] + small_constant)\n",
    "test_encoded['Log_DisbursementGross'] = np.log1p(test_encoded['DisbursementGross'])\n",
    "test_encoded['Log_GrAppv'] = np.log1p(test_encoded['GrAppv'])\n",
    "test_encoded['Log_SBA_Appv'] = np.log1p(test_encoded['SBA_Appv'])\n",
    "test_encoded['Log_BalanceGross'] = np.log1p(test_encoded['BalanceGross'])\n",
    "test_encoded['TotalJobs'] = test_encoded['CreateJob'] + test_encoded['RetainedJob']\n",
    "#train_encoded['Loan_Efficiency'] = train_encoded['DisbursementGross'] / (train_encoded['CreateJob'] + train_encoded['RetainedJob'] + 1)\n",
    "# Calculate 'LoanToIncomeRatio' as a ratio of 'SBA_Appv' to 'DisbursementGross'\n",
    "test_encoded['IncomeToLoanRatio'] = test_encoded['DisbursementGross'] / test_encoded['SBA_Appv']\n",
    "# Calculate 'LoanToEmployeesRatio' as a ratio of 'SBA_Appv' to 'NoEmp'\n",
    "test_encoded['EmployeesToLoanRatio'] = test_encoded['NoEmp'] / test_encoded['SBA_Appv']\n",
    "# Create a binary feature to indicate loans with a balance ('BalanceGross' > 0)\n",
    "#train_encoded['HasBalance'] = (train_encoded['BalanceGross'] > 0).astype(int)\n",
    "# Calculate 'LoanPerJob' as a ratio of 'SBA_Appv' to 'TotalJobs'\n",
    "test_encoded['JobPerLoan'] = test_encoded['TotalJobs'] / test_encoded['SBA_Appv'] \n",
    "# Calculate SBA's Gaurenteed Portion of Approved Loan\n",
    "test_encoded['Gauren_SBA_Appv'] = test_encoded['GrAppv'] / test_encoded['SBA_Appv']\n",
    "# Filter the DataFrame to include only the relevant rows\n",
    "default_group = test_encoded[test_encoded['MIS_Status'].isin([0, 1])]\n",
    "# Calculate the total number of loans in the filtered group\n",
    "total_loans = len(default_group)\n",
    "# Calculate the number of defaults (CHGOFF) in the filtered group\n",
    "default_loans = len(default_group[default_group['MIS_Status'] == 1])\n",
    "# Calculate the default rate as a percentage\n",
    "default_rate = (default_loans / total_loans) * 100\n",
    "# Create a new feature 'DefaultRate' with the calculated default rate\n",
    "test_encoded['DefaultRate'] = default_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City', 'State', 'Zip', 'Bank', 'BankState', 'NAICS', 'NoEmp',\n",
       "       'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural',\n",
       "       'RevLineCr', 'LowDoc', 'DisbursementGross', 'BalanceGross', 'GrAppv',\n",
       "       'SBA_Appv', 'MIS_Status', 'Log_DisbursementGross', 'Log_GrAppv',\n",
       "       'Log_SBA_Appv', 'Log_BalanceGross', 'TotalJobs', 'IncomeToLoanRatio',\n",
       "       'EmployeesToLoanRatio', 'JobPerLoan', 'Gauren_SBA_Appv', 'DefaultRate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_encoded.copy()\n",
    "X_test = test_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['MIS_Status']\n",
    "X_train.drop(columns='MIS_Status', axis=1, inplace=True)\n",
    "y_test = X_test['MIS_Status']\n",
    "X_test.drop(columns='MIS_Status', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_data = lgb.Dataset(data=X_train, label=y_train, params={\"verbose\":-1})\n",
    "test_data = lgb.Dataset(data=X_test, label=y_test, params={\"verbose\":-1})\n",
    "lgb_clf = lgb.train(params={\"verbose\":-1},\n",
    "                    train_set=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on Test dataset: 0.8205511277259651\n",
      "AUC score on Train dataset: 0.8468756526040521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"AUC score on Test dataset:\", roc_auc_score(y_test, lgb_clf.predict(X_test)))\n",
    "print(\"AUC score on Train dataset:\", roc_auc_score(y_train, lgb_clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import LightGBMPruningCallback\n",
    "import tqdm as notebook_tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "study_model_iteractions = {}\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        # Refer to the Official guide : https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "        \"num_iterations\": 10000,\n",
    "        \"num_threads\": 16,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, step=0.05),\n",
    "        #\"num_leaves\": trial.suggest_int(\"num_leaves\", 50, 150, step=5),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 700, step=10),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15, step=2),\n",
    "        #\"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 100, 1000, step=100),\n",
    "        ##############################\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-2, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-2, 10.0, log=True),\n",
    "        #\"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        #\"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        #\"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.01, 0.1, step=0.01),\n",
    "        #\"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.01, 0.1, step=0.01),\n",
    "        ########################\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.8, 1.0, step=0.1),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [5]),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.8, 1.0, step=0.1),\n",
    "        #######################\n",
    "        \"is_unbalance\": trial.suggest_categorical(\"is_unbalance\",[True, False]),\n",
    "        ########################\n",
    "        \"verbose\": -1,\n",
    "        \"objective\":\"binary\",\n",
    "        \"metric\":\"auc\",\n",
    "        \"num_threads\": 12\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    cv_iteractions = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(data=X_train, label=y_train, params={\"verbose\":-1}, categorical_feature=categorical_columns)\n",
    "        valid_data = lgb.Dataset(data=X_test, label=y_test, params={\"verbose\":-1}, categorical_feature=categorical_columns)\n",
    "        lgb_clf = lgb.train(params=param_grid,\n",
    "                            train_set=train_data,\n",
    "                            valid_sets=[valid_data],\n",
    "                            categorical_feature=categorical_columns,\n",
    "                            callbacks=[LightGBMPruningCallback(trial, \"auc\"),\n",
    "                                        lgb.early_stopping(stopping_rounds=5)]  \n",
    "                            )\n",
    "        preds = lgb_clf.predict(X_test)\n",
    "        cv_scores[idx] = roc_auc_score(y_test, preds)\n",
    "        cv_iteractions[idx] = lgb_clf.best_iteration\n",
    "    \n",
    "    study_model_iteractions[trial.number] = np.mean(cv_iteractions)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:42:35,448] A new study created in memory with name: LGBM Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.801753\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.800155\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.802386\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.800114\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.802763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:42:49,240] Trial 0 finished with value: 0.8014343348349386 and parameters: {'learning_rate': 0.21000000000000002, 'num_leaves': 600, 'max_depth': 15, 'min_data_in_leaf': 800, 'lambda_l1': 0.5019369632951083, 'lambda_l2': 0.02254125301802005, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': False}. Best is trial 0 with value: 0.8014343348349386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.80378\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.802099\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.804749\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.80121\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's auc: 0.804938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:43:06,251] Trial 1 finished with value: 0.8033552839768964 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 120, 'max_depth': 15, 'min_data_in_leaf': 600, 'lambda_l1': 1.0009992511791672, 'lambda_l2': 2.8993975320767986, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 0.8, 'is_unbalance': False}. Best is trial 1 with value: 0.8033552839768964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.802776\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.801972\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.804005\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.801175\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.802756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:43:22,716] Trial 2 finished with value: 0.802536988114316 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 330, 'max_depth': 13, 'min_data_in_leaf': 400, 'lambda_l1': 0.4946893198798722, 'lambda_l2': 0.012401785995639918, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 1 with value: 0.8033552839768964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.781565\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.782946\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[840]\tvalid_0's auc: 0.805161\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.781704\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1189]\tvalid_0's auc: 0.805866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:44:30,935] Trial 3 finished with value: 0.7914484583276552 and parameters: {'learning_rate': 0.01, 'num_leaves': 350, 'max_depth': 13, 'min_data_in_leaf': 600, 'lambda_l1': 0.11848544467399574, 'lambda_l2': 0.04070126082495083, 'bagging_fraction': 0.9, 'bagging_freq': 5, 'feature_fraction': 0.8, 'is_unbalance': False}. Best is trial 1 with value: 0.8033552839768964.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.803622\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.802773\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.80513\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's auc: 0.802192\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.805079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:44:43,169] Trial 4 finished with value: 0.8037592499384228 and parameters: {'learning_rate': 0.21000000000000002, 'num_leaves': 680, 'max_depth': 9, 'min_data_in_leaf': 500, 'lambda_l1': 0.5202237597210938, 'lambda_l2': 0.010216851864761053, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 0.8, 'is_unbalance': False}. Best is trial 4 with value: 0.8037592499384228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.803005\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.801062\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.805054\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.802001\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's auc: 0.804402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:44:58,673] Trial 5 finished with value: 0.803104618211891 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 500, 'max_depth': 11, 'min_data_in_leaf': 300, 'lambda_l1': 0.9787974235525188, 'lambda_l2': 0.22133344374978123, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 4 with value: 0.8037592499384228.\n",
      "[I 2023-12-08 21:44:59,165] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:44:59,666] Trial 7 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:00,127] Trial 8 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:00,662] Trial 9 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:01,248] Trial 10 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:01,785] Trial 11 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:02,292] Trial 12 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:02,892] Trial 13 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:03,398] Trial 14 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:03,947] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:04,514] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:05,029] Trial 17 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.801936\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.800774\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.803156\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.800259\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.802773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:45:16,281] Trial 18 finished with value: 0.8017795797707208 and parameters: {'learning_rate': 0.26, 'num_leaves': 550, 'max_depth': 15, 'min_data_in_leaf': 400, 'lambda_l1': 0.835277936148312, 'lambda_l2': 0.4484188292304997, 'bagging_fraction': 0.9, 'bagging_freq': 5, 'feature_fraction': 0.8, 'is_unbalance': False}. Best is trial 4 with value: 0.8037592499384228.\n",
      "[I 2023-12-08 21:45:16,781] Trial 19 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:17,271] Trial 20 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.803245\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.801758\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.805084\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.80141\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.804334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:45:31,730] Trial 21 finished with value: 0.8031661198776447 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 700, 'max_depth': 11, 'min_data_in_leaf': 200, 'lambda_l1': 1.035723033799241, 'lambda_l2': 0.30617848486664295, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 4 with value: 0.8037592499384228.\n",
      "[I 2023-12-08 21:45:32,232] Trial 22 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:32,743] Trial 23 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:33,306] Trial 24 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:33,876] Trial 25 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.803323\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.80233\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.806436\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.80291\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.804379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:45:50,078] Trial 26 finished with value: 0.8038756746130302 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 530, 'max_depth': 11, 'min_data_in_leaf': 200, 'lambda_l1': 1.7269826111545732, 'lambda_l2': 0.25399485674500827, 'bagging_fraction': 0.9, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 26 with value: 0.8038756746130302.\n",
      "[I 2023-12-08 21:45:50,552] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:51,076] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:51,684] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:45:52,267] Trial 30 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.803795\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.80167\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.804703\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.801216\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.803767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:46:07,240] Trial 31 finished with value: 0.8030301640981194 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 700, 'max_depth': 11, 'min_data_in_leaf': 200, 'lambda_l1': 1.1416126323028555, 'lambda_l2': 0.28495095797392916, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 26 with value: 0.8038756746130302.\n",
      "[I 2023-12-08 21:46:07,749] Trial 32 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:46:08,365] Trial 33 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:46:08,948] Trial 34 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.803714\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.802915\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.806026\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.802304\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.805928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:46:22,934] Trial 35 finished with value: 0.8041774035640923 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 460, 'max_depth': 13, 'min_data_in_leaf': 200, 'lambda_l1': 1.342771014406765, 'lambda_l2': 0.17194645073771586, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 35 with value: 0.8041774035640923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.804801\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.802438\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.805844\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.802031\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.80529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:46:36,763] Trial 36 finished with value: 0.8040808577349583 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 370, 'max_depth': 13, 'min_data_in_leaf': 300, 'lambda_l1': 1.6126827444489302, 'lambda_l2': 0.025335997293718625, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 35 with value: 0.8041774035640923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.804285\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.802437\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.804624\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.80203\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.804739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:46:48,885] Trial 37 finished with value: 0.8036230517718547 and parameters: {'learning_rate': 0.21000000000000002, 'num_leaves': 370, 'max_depth': 13, 'min_data_in_leaf': 300, 'lambda_l1': 1.4814065474915035, 'lambda_l2': 0.0101627935417404, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 35 with value: 0.8041774035640923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.803741\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.802788\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.805414\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.802431\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.804922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:47:02,067] Trial 38 finished with value: 0.8038592033079436 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 450, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 1.4653769936025254, 'lambda_l2': 0.016763981276730917, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 35 with value: 0.8041774035640923.\n",
      "[I 2023-12-08 21:47:02,664] Trial 39 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.803467\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.802823\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.805389\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.802381\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.805246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:47:15,506] Trial 40 finished with value: 0.8038611936409554 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 460, 'max_depth': 13, 'min_data_in_leaf': 200, 'lambda_l1': 1.429256789911889, 'lambda_l2': 0.016027603901618212, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 35 with value: 0.8041774035640923.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.803967\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.803668\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.805716\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.802581\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.805068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:47:28,105] Trial 41 finished with value: 0.8041998833588033 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 380, 'max_depth': 13, 'min_data_in_leaf': 200, 'lambda_l1': 1.6486809750973213, 'lambda_l2': 0.01646153811045168, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 41 with value: 0.8041998833588033.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.803898\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.802848\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.805099\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.802456\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.806274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:47:41,205] Trial 42 finished with value: 0.8041148605161605 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 370, 'max_depth': 13, 'min_data_in_leaf': 200, 'lambda_l1': 1.3927190261293332, 'lambda_l2': 0.027011193607958475, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 41 with value: 0.8041998833588033.\n",
      "[I 2023-12-08 21:47:41,786] Trial 43 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:47:42,351] Trial 44 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:47:42,986] Trial 45 pruned. Trial was pruned at iteration 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:47:43,536] Trial 46 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:47:44,504] Trial 47 pruned. Trial was pruned at iteration 11.\n",
      "[I 2023-12-08 21:47:45,069] Trial 48 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:47:45,607] Trial 49 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:47:46,186] Trial 50 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.804145\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.802708\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.805502\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.80265\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.805537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:48:00,574] Trial 51 finished with value: 0.8041085724684789 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 470, 'max_depth': 13, 'min_data_in_leaf': 200, 'lambda_l1': 1.4282758342763142, 'lambda_l2': 0.015256916081259004, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 41 with value: 0.8041998833588033.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.804738\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.802608\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.806023\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.802948\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.805228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:48:14,239] Trial 52 finished with value: 0.8043088881883189 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 380, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 2.0419310805102273, 'lambda_l2': 0.013339835168278942, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 52 with value: 0.8043088881883189.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.804881\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.803504\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.805555\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.802867\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:48:26,137] Trial 53 finished with value: 0.8043295959122133 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 390, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 2.2947110854879846, 'lambda_l2': 0.012044752572340792, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 53 with value: 0.8043295959122133.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.804841\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.803559\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.802314\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.80545\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.802328\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.805348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:48:39,427] Trial 54 finished with value: 0.8037996367779854 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 480, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 3.10337012237072, 'lambda_l2': 0.012731435462823166, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 53 with value: 0.8043295959122133.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.804139\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.802798\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.805209\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.80292\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.805035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:48:52,318] Trial 55 finished with value: 0.804020187950365 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 430, 'max_depth': 15, 'min_data_in_leaf': 100, 'lambda_l1': 2.177739790346209, 'lambda_l2': 0.010710164798534955, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 53 with value: 0.8043295959122133.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.803373\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.801321\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.804504\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.802026\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:02,209] Trial 56 finished with value: 0.8031707416285586 and parameters: {'learning_rate': 0.21000000000000002, 'num_leaves': 390, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 1.202977610240069, 'lambda_l2': 0.015309728521150751, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 53 with value: 0.8043295959122133.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.80463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:02,772] Trial 57 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:03,528] Trial 58 pruned. Trial was pruned at iteration 4.\n",
      "[I 2023-12-08 21:49:04,101] Trial 59 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:49:04,766] Trial 60 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:05,309] Trial 61 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:07,225] Trial 62 pruned. Trial was pruned at iteration 35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:08,031] Trial 63 pruned. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.804756\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.803031\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.806228\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.802835\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:20,314] Trial 64 finished with value: 0.8044799022503313 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 290, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.9109895189675501, 'lambda_l2': 0.024978280416284533, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 64 with value: 0.8044799022503313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.80555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:20,831] Trial 65 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.802684\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.801614\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.804006\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:28,608] Trial 66 pruned. Trial was pruned at iteration 42.\n",
      "[I 2023-12-08 21:49:29,178] Trial 67 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:29,712] Trial 68 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:49:30,218] Trial 69 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:49:30,862] Trial 70 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:31,424] Trial 71 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:49:32,015] Trial 72 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:32,564] Trial 73 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:49:33,231] Trial 74 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:33,747] Trial 75 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.804304\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.803467\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.805369\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.802902\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.80616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:49:47,174] Trial 76 finished with value: 0.8044403955845695 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 370, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 2.397682879917814, 'lambda_l2': 0.038209738563430115, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 64 with value: 0.8044799022503313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.803825\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.802664\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.805499\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.802864\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.805323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:50:00,567] Trial 77 finished with value: 0.8040350553168318 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 440, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 2.3660595694696056, 'lambda_l2': 0.06303039857904925, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 64 with value: 0.8044799022503313.\n",
      "[I 2023-12-08 21:50:01,072] Trial 78 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:50:03,298] Trial 79 pruned. Trial was pruned at iteration 43.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:50:04,992] Trial 80 pruned. Trial was pruned at iteration 32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.804127\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.803452\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.805607\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.802014\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.805395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:50:17,770] Trial 81 finished with value: 0.8041186762340986 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 380, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 1.594821830830782, 'lambda_l2': 0.02356400222007002, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 64 with value: 0.8044799022503313.\n",
      "[I 2023-12-08 21:50:18,350] Trial 82 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.804352\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.802656\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.8059\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.802359\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.805573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:50:31,396] Trial 83 finished with value: 0.8041679322627875 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 410, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 1.3077730480104564, 'lambda_l2': 0.011639258303826628, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 64 with value: 0.8044799022503313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.804487\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.803316\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.805743\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.80337\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.806141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:50:44,546] Trial 84 finished with value: 0.8046114150178705 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 380, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.8143630422709964, 'lambda_l2': 0.011498433150379532, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n",
      "[I 2023-12-08 21:50:45,077] Trial 85 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:50:45,579] Trial 86 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:50:46,128] Trial 87 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.804275\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.80265\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.806545\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.802561\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:50:58,776] Trial 88 finished with value: 0.8041832212938385 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 380, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.7788412929204277, 'lambda_l2': 0.014643246918487122, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.804886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:50:59,294] Trial 89 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.804426\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.80292\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.805455\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.802665\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.80544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:51:11,559] Trial 90 finished with value: 0.8041811259091926 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 350, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.6412952497291128, 'lambda_l2': 0.018308171082697132, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:51:13,483] Trial 91 pruned. Trial was pruned at iteration 45.\n",
      "[I 2023-12-08 21:51:14,092] Trial 92 pruned. Trial was pruned at iteration 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:51:14,692] Trial 93 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.804519\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.803157\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.805975\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.803126\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:51:26,976] Trial 94 finished with value: 0.8044613715959799 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 330, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.6151547747185434, 'lambda_l2': 0.01754409574030045, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.80553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:51:27,507] Trial 95 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.804509\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.80296\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.806625\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.802026\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.805825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:51:40,628] Trial 96 finished with value: 0.8043891457148222 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 350, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.6018146118800104, 'lambda_l2': 0.029038500955045038, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n",
      "[I 2023-12-08 21:51:41,138] Trial 97 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.804657\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.802901\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.806131\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.80213\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.805602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:51:52,853] Trial 98 finished with value: 0.8042841885317843 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 350, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.6177964142618628, 'lambda_l2': 0.02032115275372723, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.804277\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.802906\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.806074\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.802501\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.805408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:05,385] Trial 99 finished with value: 0.8042331470130373 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 380, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.739359805831142, 'lambda_l2': 0.020825185036235816, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n",
      "[I 2023-12-08 21:52:05,979] Trial 100 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:06,818] Trial 101 pruned. Trial was pruned at iteration 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:08,585] Trial 102 pruned. Trial was pruned at iteration 34.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:09,701] Trial 103 pruned. Trial was pruned at iteration 15.\n",
      "[I 2023-12-08 21:52:10,273] Trial 104 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.804305\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.802997\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.806005\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.802636\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.805375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:22,608] Trial 105 finished with value: 0.8042636009702996 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 390, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.58797631661029, 'lambda_l2': 0.034142593618893366, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n",
      "[I 2023-12-08 21:52:23,149] Trial 106 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:52:23,716] Trial 107 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:24,266] Trial 108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:52:24,799] Trial 109 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:52:25,299] Trial 110 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:26,805] Trial 111 pruned. Trial was pruned at iteration 24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:27,932] Trial 112 pruned. Trial was pruned at iteration 15.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:28,799] Trial 113 pruned. Trial was pruned at iteration 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:30,765] Trial 114 pruned. Trial was pruned at iteration 40.\n",
      "[I 2023-12-08 21:52:31,298] Trial 115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:52:31,815] Trial 116 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:33,065] Trial 117 pruned. Trial was pruned at iteration 17.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:34,231] Trial 118 pruned. Trial was pruned at iteration 17.\n",
      "[I 2023-12-08 21:52:34,754] Trial 119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:52:35,282] Trial 120 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:36,264] Trial 121 pruned. Trial was pruned at iteration 12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:37,451] Trial 122 pruned. Trial was pruned at iteration 17.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:38,497] Trial 123 pruned. Trial was pruned at iteration 12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:39,864] Trial 124 pruned. Trial was pruned at iteration 22.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:41,030] Trial 125 pruned. Trial was pruned at iteration 15.\n",
      "[I 2023-12-08 21:52:41,564] Trial 126 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.804471\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.80297\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.806138\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.802348\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.805721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:54,062] Trial 127 finished with value: 0.8043295859541792 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 370, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 1.7461681705520031, 'lambda_l2': 0.01926038611893716, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n",
      "[I 2023-12-08 21:52:54,645] Trial 128 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:55,233] Trial 129 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:55,762] Trial 130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:52:56,432] Trial 131 pruned. Trial was pruned at iteration 4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:57,216] Trial 132 pruned. Trial was pruned at iteration 6.\n",
      "[I 2023-12-08 21:52:57,812] Trial 133 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:52:58,862] Trial 134 pruned. Trial was pruned at iteration 13.\n",
      "[I 2023-12-08 21:52:59,461] Trial 135 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:00,013] Trial 136 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:00,561] Trial 137 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:53:01,138] Trial 138 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:53:01,736] Trial 139 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:02,294] Trial 140 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:53:02,877] Trial 141 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:03,628] Trial 142 pruned. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:04,350] Trial 143 pruned. Trial was pruned at iteration 5.\n",
      "[I 2023-12-08 21:53:04,928] Trial 144 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:53:05,527] Trial 145 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:06,044] Trial 146 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:53:06,577] Trial 147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:53:07,194] Trial 148 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:53:07,700] Trial 149 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:53:08,209] Trial 150 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:09,122] Trial 151 pruned. Trial was pruned at iteration 9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.80413\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.802546\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.805645\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.803397\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.804714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:22,341] Trial 152 finished with value: 0.8040862766933283 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 410, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 1.612987060411111, 'lambda_l2': 0.015221657841184707, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:23,908] Trial 153 pruned. Trial was pruned at iteration 29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:25,424] Trial 154 pruned. Trial was pruned at iteration 29.\n",
      "[I 2023-12-08 21:53:25,975] Trial 155 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:28,424] Trial 156 pruned. Trial was pruned at iteration 52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:29,219] Trial 157 pruned. Trial was pruned at iteration 6.\n",
      "[I 2023-12-08 21:53:29,757] Trial 158 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:30,575] Trial 159 pruned. Trial was pruned at iteration 6.\n",
      "[I 2023-12-08 21:53:31,124] Trial 160 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.804262\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.80356\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.806071\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.802137\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.805845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:43,429] Trial 161 finished with value: 0.804374785695438 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 380, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 1.6715621952706468, 'lambda_l2': 0.021809221548346774, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.803859\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:48,260] Trial 162 pruned. Trial was pruned at iteration 58.\n",
      "[I 2023-12-08 21:53:48,806] Trial 163 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:49,638] Trial 164 pruned. Trial was pruned at iteration 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:53:50,779] Trial 165 pruned. Trial was pruned at iteration 15.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.804274\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.802988\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.805461\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.802233\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.80544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:03,142] Trial 166 finished with value: 0.8040793643469211 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 380, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 1.1302267432332307, 'lambda_l2': 0.024978273082551322, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n",
      "[I 2023-12-08 21:54:03,693] Trial 167 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:04,268] Trial 168 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:05,257] Trial 169 pruned. Trial was pruned at iteration 11.\n",
      "[I 2023-12-08 21:54:05,802] Trial 170 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.804911\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.803431\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.805941\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.802867\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.804491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:18,527] Trial 171 finished with value: 0.8043279781797896 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 380, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 1.676290197015179, 'lambda_l2': 0.022992018078717202, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n",
      "[I 2023-12-08 21:54:19,140] Trial 172 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:20,020] Trial 173 pruned. Trial was pruned at iteration 9.\n",
      "[I 2023-12-08 21:54:20,584] Trial 174 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:21,326] Trial 175 pruned. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.804331\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.802252\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.80525\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.803179\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.806059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:34,251] Trial 176 finished with value: 0.8042139811792938 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 400, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 2.0348896359034083, 'lambda_l2': 0.023931463533413487, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n",
      "[I 2023-12-08 21:54:34,804] Trial 177 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:54:35,430] Trial 178 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:35,986] Trial 179 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:54:36,561] Trial 180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:54:37,118] Trial 181 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:37,982] Trial 182 pruned. Trial was pruned at iteration 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:38,865] Trial 183 pruned. Trial was pruned at iteration 8.\n",
      "[I 2023-12-08 21:54:39,456] Trial 184 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:40,291] Trial 185 pruned. Trial was pruned at iteration 7.\n",
      "[I 2023-12-08 21:54:40,849] Trial 186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:54:41,384] Trial 187 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:54:41,915] Trial 188 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:54:42,492] Trial 189 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:43,537] Trial 190 pruned. Trial was pruned at iteration 12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:44,804] Trial 191 pruned. Trial was pruned at iteration 17.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:45,822] Trial 192 pruned. Trial was pruned at iteration 12.\n",
      "[I 2023-12-08 21:54:46,351] Trial 193 pruned. Trial was pruned at iteration 0.\n",
      "[I 2023-12-08 21:54:46,997] Trial 194 pruned. Trial was pruned at iteration 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:47,840] Trial 195 pruned. Trial was pruned at iteration 8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:49,538] Trial 196 pruned. Trial was pruned at iteration 29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:54:50,306] Trial 197 pruned. Trial was pruned at iteration 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.804164\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.803334\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.80593\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.802057\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.805321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:55:03,159] Trial 198 finished with value: 0.8041612288067324 and parameters: {'learning_rate': 0.16000000000000003, 'num_leaves': 390, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.5597494879262164, 'lambda_l2': 0.019873106892296235, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True}. Best is trial 84 with value: 0.8046114150178705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 21:55:04,753] Trial 199 pruned. Trial was pruned at iteration 29.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Classifier\")\n",
    "func = lambda trial: objective(trial, X_train, y_train)\n",
    "study.optimize(func, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming you have a variable named 'best_params' containing the best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "with open('best_params.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': -1,\n",
       " 'objective': 'binary',\n",
       " 'metric': 'auc',\n",
       " 'learning_rate': 0.16000000000000003,\n",
       " 'num_leaves': 380,\n",
       " 'max_depth': 13,\n",
       " 'min_data_in_leaf': 100,\n",
       " 'lambda_l1': 0.8143630422709964,\n",
       " 'lambda_l2': 0.011498433150379532,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 5,\n",
       " 'feature_fraction': 1.0,\n",
       " 'is_unbalance': True,\n",
       " 'num_iterations': 63}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_optimal_threshold(classifier, X, y):\n",
    "    # Predict probabilities\n",
    "    y_pred_proba = classifier.predict(X)\n",
    "    \n",
    "    # Set a range of thresholds to test\n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    \n",
    "    # Find the threshold that maximizes the F1 score\n",
    "    for threshold in thresholds:\n",
    "      y_pred = (y_pred_proba > threshold).astype(int)\n",
    "      f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "      if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (AUC): 0.80461\n",
      "\tBest params:\n",
      "\t\tlearning_rate: 0.16000000000000003\n",
      "\t\tnum_leaves: 380\n",
      "\t\tmax_depth: 13\n",
      "\t\tmin_data_in_leaf: 100\n",
      "\t\tlambda_l1: 0.8143630422709964\n",
      "\t\tlambda_l2: 0.011498433150379532\n",
      "\t\tbagging_fraction: 1.0\n",
      "\t\tbagging_freq: 5\n",
      "\t\tfeature_fraction: 1.0\n",
      "\t\tis_unbalance: True\n",
      "Best model best_iteration: 63.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\tBest value (AUC): {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")\n",
    "\n",
    "print(\"Best model best_iteration:\", study_model_iteractions[study.best_trial.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': -1, 'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.16000000000000003, 'num_leaves': 380, 'max_depth': 13, 'min_data_in_leaf': 100, 'lambda_l1': 0.8143630422709964, 'lambda_l2': 0.011498433150379532, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': True, 'num_iterations': 63}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\"verbose\": -1,\n",
    "                \"objective\":\"binary\",\n",
    "                \"metric\":\"auc\"\n",
    "            }\n",
    "for key,val in study.best_params.items():\n",
    "    best_params[key] = val\n",
    "\n",
    "best_params[\"num_iterations\"] = int(study_model_iteractions[study.best_trial.number])\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with parameters found using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = lgb.Dataset(data=X_train, label=y_train, params={\"verbose\":-1}, categorical_feature=categorical_columns)\n",
    "test_data = lgb.Dataset(data=X_test, label=y_test, params={\"verbose\":-1}, categorical_feature=categorical_columns)\n",
    "best_lgb = lgb.train(params=best_params,\n",
    "                    train_set=train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on Test dataset: 0.8080452240164088\n",
      "AUC score on Train dataset: 0.8479345099436233\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC score on Test dataset:\", roc_auc_score(y_test, best_lgb.predict(X_test)))\n",
    "print(\"AUC score on Train dataset:\", roc_auc_score(y_train, best_lgb.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_optimal_threshold(classifier, X, y):\n",
    "    # Predict probabilities\n",
    "    y_pred_proba = classifier.predict(X)\n",
    "    \n",
    "    # Set a range of thresholds to test\n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    \n",
    "    # Find the threshold that maximizes the F1 score\n",
    "    for threshold in thresholds:\n",
    "      y_pred = (y_pred_proba > threshold).astype(int)\n",
    "      f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "      if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "    return best_threshold\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_optimal_threshold(best_lgb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.6879352668818348\n",
      "Best threshold: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Assuming best_lgb is the trained LightGBM model and X_test, y_test are defined\n",
    "\n",
    "# Get the predicted probabilities for the positive class (class 1)\n",
    "y_pred_proba = best_lgb.predict(X_test)\n",
    "\n",
    "# Set a range of thresholds to test\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(\"Best F1 score:\", best_f1)\n",
    "print(\"Best threshold:\", best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[179678  18222]\n",
      " [ 23150  19027]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Get the predicted probabilities for the positive class (class 1) from the test set\n",
    "y_pred_proba = best_lgb.predict(X_test)\n",
    "\n",
    "# Use the threshold obtained earlier to predict binary labels\n",
    "threshold = best_threshold\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# Construct the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming you have a variable named 'best_params' containing the best hyperparameters\n",
    "best_params = best_params\n",
    "\n",
    "with open('best_params.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_optimal_threshold(classifier, X, y):\n",
    "    # Predict probabilities\n",
    "    y_pred_proba = classifier.predict(X)\n",
    "    \n",
    "    # Set a range of thresholds to test\n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    \n",
    "    # Find the threshold that maximizes the F1 score\n",
    "    for threshold in thresholds:\n",
    "      y_pred = (y_pred_proba > threshold).astype(int)\n",
    "      f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "      if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "from copy import deepcopy\n",
    "\n",
    "def train_model(df):\n",
    "    \"\"\"\n",
    "    Train sample model and save artifacts\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from optuna.integration import LightGBMPruningCallback\n",
    "    import tqdm as notebook_tqdm\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import optuna\n",
    "    import warnings\n",
    "    import pickle\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.preprocessing import FunctionTransformer\n",
    "    from sklearn.metrics import average_precision_score\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    \n",
    "    \n",
    "    target_col = \"MIS_Status\"\n",
    "    cols_to_drop = ['City', 'State', 'Zip','Bank', 'BankState', 'LowDoc','RevLineCr','MIS_Status']\n",
    "    # Removing the index column\n",
    "    if \"index\" in df.columns:\n",
    "        df.drop(columns=\"index\", inplace=True)\n",
    "    y = df[target_col] if target_col in df.columns else None\n",
    "    X = df.drop(columns=[target_col]) if target_col in df.columns else df.copy()\n",
    "\n",
    "\n",
    "    # Relacing Missing values\n",
    "    \n",
    "    for i in df['RevLineCr']:\n",
    "      if i not in ['Y','N']:\n",
    "        df['RevLineCr'].replace(i,'N',inplace=True)\n",
    "        print(\"RevLineCr\",df['RevLineCr'].unique())\n",
    "\n",
    "    for i in df['LowDoc']:\n",
    "      if i not in ['Y','N']:\n",
    "        df['LowDoc'].replace(i,'N',inplace=True)\n",
    "        print(\"LowDoc\",df['LowDoc'].unique())\n",
    "\n",
    "    for i in df['NewExist']:\n",
    "      if i not in [1,2]:\n",
    "        df['NewExist'].replace(i,None,inplace=True)\n",
    "        print(\"NewExist\",df['NewExist'].unique())\n",
    "\n",
    "\n",
    "    category_cols=['City', 'State', 'Bank', 'BankState', 'RevLineCr', 'LowDoc','NewExist']\n",
    "    for column in category_cols:\n",
    "        df[column]=df[column].fillna(df[column].mode()[0])\n",
    "\n",
    "    # Target encoding the categorical columns\n",
    "    categorical_columns = ['City', 'State', 'Bank', 'BankState', 'RevLineCr', 'LowDoc','NewExist']\n",
    "    encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "    encoder.fit(df[categorical_columns], df['MIS_Status'])\n",
    "    train_encoded = encoder.transform(df[categorical_columns])\n",
    "    train_encoded = train_encoded.add_suffix('_trg')\n",
    "    #train_encoded = pd.concat([train_encoded, data], axis=1)\n",
    "    train_encoded = pd.concat([train_encoded, df], axis=1)\n",
    "    for column in categorical_columns:\n",
    "        train_encoded[column + \"_trg\"].fillna(train_encoded[column + \"_trg\"].mean(), inplace=True)\n",
    "    \n",
    "    # Renaming the columns\n",
    "    #train_encoded.rename(columns={col: col + \"_trg\" if col in categorical_columns else col for col in train_encoded.columns}, inplace=False)\n",
    "    print(train_encoded.columns)\n",
    "    \n",
    "\n",
    "\n",
    "    # Adding Features\n",
    "    import numpy as np\n",
    "    # Apply the log transformation to the specific feature in your training data\n",
    "    small_constant = 1e-10  # You can adjust this constant as needed\n",
    "    # df['LogColumn'] = np.log(df['OriginalColumn'] + small_constant)\n",
    "    train_encoded['Log_DisbursementGross'] = np.log1p(train_encoded['DisbursementGross'])\n",
    "    train_encoded['Log_GrAppv'] = np.log1p(train_encoded['GrAppv'])\n",
    "    train_encoded['Log_SBA_Appv'] = np.log1p(train_encoded['SBA_Appv'])\n",
    "    train_encoded['Log_BalanceGross'] = np.log1p(train_encoded['BalanceGross'])\n",
    "    train_encoded['TotalJobs'] = train_encoded['CreateJob'] + train_encoded['RetainedJob']\n",
    "    #train_encoded['Loan_Efficiency'] = train_encoded['DisbursementGross'] / (train_encoded['CreateJob'] + train_encoded['RetainedJob'] + 1)\n",
    "    # Calculate 'LoanToIncomeRatio' as a ratio of 'SBA_Appv' to 'DisbursementGross'\n",
    "    train_encoded['IncomeToLoanRatio'] = train_encoded['DisbursementGross'] / train_encoded['SBA_Appv']\n",
    "    # Calculate 'LoanToEmployeesRatio' as a ratio of 'SBA_Appv' to 'NoEmp'\n",
    "    train_encoded['EmployeesToLoanRatio'] = train_encoded['NoEmp'] / train_encoded['SBA_Appv']\n",
    "    # Create a binary feature to indicate loans with a balance ('BalanceGross' > 0)\n",
    "    #train_encoded['HasBalance'] = (train_encoded['BalanceGross'] > 0).astype(int)\n",
    "    # Calculate 'LoanPerJob' as a ratio of 'SBA_Appv' to 'TotalJobs'\n",
    "    train_encoded['JobPerLoan'] = train_encoded['TotalJobs'] / train_encoded['SBA_Appv'] \n",
    "    # Calculate SBA's Gaurenteed Portion of Approved Loan\n",
    "    train_encoded['Gauren_SBA_Appv'] = train_encoded['GrAppv'] / train_encoded['SBA_Appv']\n",
    "\n",
    "    \n",
    "    # Scaling the numerical columns\n",
    "    numerical_columns = [ 'NoEmp', 'CreateJob', 'RetainedJob', 'GrAppv', 'SBA_Appv', 'DisbursementGross', 'BalanceGross',\n",
    "                        'Log_DisbursementGross', 'Log_GrAppv', 'Log_SBA_Appv', 'Log_BalanceGross','TotalJobs','IncomeToLoanRatio', \n",
    "                        'EmployeesToLoanRatio', 'JobPerLoan', 'Gauren_SBA_Appv']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    #fit and transform separately\n",
    "    scaler.fit(train_encoded[numerical_columns])\n",
    "    train_encoded[numerical_columns] = scaler.transform(train_encoded[numerical_columns])\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    study_model_iteractions = {}\n",
    "\n",
    "    def objective(trial, X, y):\n",
    "     \n",
    "      param_grid = {\n",
    "        # Refer to the Official guide : https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "        \"num_iterations\": 10000,\n",
    "        \"num_threads\": 16,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, step=0.05),\n",
    "        #\"num_leaves\": trial.suggest_int(\"num_leaves\", 50, 150, step=5),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        #\"max_depth\": trial.suggest_int(\"max_depth\", 5, 20, step=2),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 100, 1000, step=100),\n",
    "        ##############################\n",
    "        #'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        #'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        #\"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.01, 0.1, step=0.01),\n",
    "        #\"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.01, 0.1, step=0.01),\n",
    "        ########################\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.8, 1.0, step=0.1),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [5]),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.8, 1.0, step=0.1),\n",
    "        #######################\n",
    "        \"is_unbalance\": trial.suggest_categorical(\"is_unbalance\",[True, False]),\n",
    "        ########################\n",
    "        \"verbose\": -1,\n",
    "        \"objective\":\"binary\",\n",
    "        \"metric\":\"auc\",\n",
    "        \"num_threads\": 12\n",
    "       }\n",
    "\n",
    "      cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "      cv_scores = np.empty(5)\n",
    "      cv_iteractions = np.empty(5)\n",
    "      for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(data=X_train, label=y_train, params={\"verbose\":-1}, categorical_feature=categorical_columns)\n",
    "        valid_data = lgb.Dataset(data=X_test, label=y_test, params={\"verbose\":-1}, categorical_feature=categorical_columns)\n",
    "        lgb_clf = lgb.train(params=param_grid,\n",
    "                            train_set=train_data,\n",
    "                            valid_sets=[valid_data],\n",
    "                            categorical_feature=categorical_columns,\n",
    "                            callbacks=[LightGBMPruningCallback(trial, \"auc\"),\n",
    "                                        lgb.early_stopping(stopping_rounds=5)]  \n",
    "                            )\n",
    "        preds = lgb_clf.predict(X_test)\n",
    "        cv_scores[idx] = roc_auc_score(y_test, preds)\n",
    "        cv_iteractions[idx] = lgb_clf.best_iteration\n",
    "    \n",
    "      study_model_iteractions[trial.number] = np.mean(cv_iteractions)\n",
    "\n",
    "      return np.mean(cv_scores)\n",
    "\n",
    "      study = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Classifier\")\n",
    "      func = lambda trial: objective(trial, X_train, y_train)\n",
    "      study.optimize(func, n_trials=200)\n",
    "\n",
    "      print(f\"\\tBest value (AUC): {study.best_value:.5f}\")\n",
    "      print(f\"\\tBest params:\")\n",
    "\n",
    "      for key, value in study.best_params.items():\n",
    "        print(f\"\\t\\t{key}: {value}\")\n",
    "\n",
    "      print(\"Best model best_iteration:\", study_model_iteractions[study.best_trial.number])\n",
    "      best_iterations = study_model_iteractions[study.best_trial.number] \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "          \n",
    "   \n",
    "      # End Todo\n",
    "    \n",
    "      # Saving the artifacts\n",
    "      artifacts_dict = {\n",
    "        \"model\": lgb_clf,\n",
    "        \"target_encoder\": encoder,\n",
    "        \"te_columns\": categorical_columns,\n",
    "        \"columns_to_train\":columns_to_train,\n",
    "        \"numerical_columns\":numerical_columns,\n",
    "        \"category_cols\": category_cols,\n",
    "        \"scaler\":scaler\n",
    "        #\"h2o_model_path\":model_path\n",
    "      }\n",
    "\n",
    "      #calculating threshold\n",
    "      if y is not None:\n",
    "        optimal_threshold = calculate_optimal_threshold(clf_, train_encoded[columns_to_train], y)\n",
    "        print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "        # Saving the threshold in artifacts\n",
    "        artifacts_dict[\"threshold\"] = optimal_threshold\n",
    "\n",
    "      artifacts_dict_file = open(\"./Artifacts/artifacts_dict_file.pkl\", \"wb\")\n",
    "      pickle.dump(obj=artifacts_dict, file=artifacts_dict_file)    \n",
    "       \n",
    "      artifacts_dict_file.close()    \n",
    "      return lgb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevLineCr ['N' 'Y' 'T' nan '1' 'R' '`' 'Q' '-' '7' '2' '4' '.' 'C']\n",
      "RevLineCr ['N' 'Y' nan '1' 'R' '`' 'Q' '-' '7' '2' '4' '.' 'C']\n",
      "RevLineCr ['N' 'Y' '1' 'R' '`' 'Q' '-' '7' '2' '4' '.' 'C']\n",
      "RevLineCr ['N' 'Y' 'R' '`' 'Q' '-' '7' '2' '4' '.' 'C']\n",
      "RevLineCr ['N' 'Y' '`' 'Q' '-' '7' '2' '4' '.' 'C']\n",
      "RevLineCr ['N' 'Y' 'Q' '-' '7' '2' '4' '.' 'C']\n",
      "RevLineCr ['N' 'Y' '-' '7' '2' '4' '.' 'C']\n",
      "RevLineCr ['N' 'Y' '7' '2' '4' '.' 'C']\n",
      "RevLineCr ['N' 'Y' '2' '4' '.' 'C']\n",
      "RevLineCr ['N' 'Y' '4' '.' 'C']\n",
      "RevLineCr ['N' 'Y' '.' 'C']\n",
      "RevLineCr ['N' 'Y' 'C']\n",
      "RevLineCr ['N' 'Y']\n",
      "LowDoc ['N' 'Y' 'C' nan 'A' 'S' 'R']\n",
      "LowDoc ['N' 'Y' nan 'A' 'S' 'R']\n",
      "LowDoc ['N' 'Y' 'A' 'S' 'R']\n",
      "LowDoc ['N' 'Y' 'S' 'R']\n",
      "LowDoc ['N' 'Y' 'R']\n",
      "LowDoc ['N' 'Y']\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None nan]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "NewExist [1.0 2.0 None]\n",
      "Index(['City_trg', 'State_trg', 'Bank_trg', 'BankState_trg', 'RevLineCr_trg',\n",
      "       'LowDoc_trg', 'NewExist_trg', 'City', 'State', 'Zip', 'Bank',\n",
      "       'BankState', 'NAICS', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob',\n",
      "       'FranchiseCode', 'UrbanRural', 'RevLineCr', 'LowDoc',\n",
      "       'DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv',\n",
      "       'MIS_Status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "        \n",
    "df = pd.read_csv(\"D:/Work/Gre/UTD/Courses/Fall/MIS6341/Softwares/Python/ml-fall-2023/Project2/SBA_loans_project_2.csv\")\n",
    "target = \"MIS_Status\"\n",
    "y = df[target]\n",
    "x = df.drop(columns=[target])\n",
    "\n",
    "# Splitting the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "df_train = X_train.copy()\n",
    "df_train[target] = y_train\n",
    "train_model(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(data):\n",
    "    \"\"\"\n",
    "    Function to score input dataset.\n",
    "    \n",
    "    Input: dataset in Pandas DataFrame format\n",
    "    Output: Python list of labels in the same order as input records\n",
    "    \n",
    "    Flow:\n",
    "        - Load artifacts\n",
    "        - Transform dataset\n",
    "        - Score dataset\n",
    "        - Return labels\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if \"index\" in data.columns:\n",
    "        data.drop(columns=\"index\", inplace=True)\n",
    "    #Load Artifacts\n",
    "    artifacts_dict_file = open(\"./Artifacts/artifacts_dict_file.pkl\", \"rb\")\n",
    "    artifacts_dict = pickle.load(file=artifacts_dict_file)\n",
    "    artifacts_dict_file.close()\n",
    "    \n",
    "\n",
    "    clf = artifacts_dict[\"model\"]\n",
    "    te = artifacts_dict[\"target_encoder\"]\n",
    "    te_columns = artifacts_dict[\"te_columns\"]\n",
    "    columns_to_score = artifacts_dict[\"columns_to_train\"]\n",
    "    threshold = artifacts_dict[\"threshold\"]\n",
    "    category_cols = artifacts_dict[\"category_cols\"]\n",
    "    numerical_columns = artifacts_dict[\"numerical_columns\"]\n",
    "    scaler = artifacts_dict[\"scaler\"]\n",
    "\n",
    "     # Replacing the missing values\n",
    "    for i in data['RevLineCr']:\n",
    "        if i not in ['Y','N']:\n",
    "            data['RevLineCr'].replace(i,'N',inplace=True)\n",
    "\n",
    "    for i in data['LowDoc']:\n",
    "        if i not in ['Y','N']:\n",
    "            data['LowDoc'].replace(i,'N',inplace=True)\n",
    "\n",
    "    for i in data['NewExist']:\n",
    "        if i not in [1,2]:\n",
    "            data['NewExist'].replace(i,None,inplace=True)\n",
    "\n",
    "    for column in category_cols:\n",
    "        data[column]=data[column].fillna(data[column].mode()[0])\n",
    "\n",
    "    \n",
    "    # 10 New Feature Extractions\n",
    "    import numpy as np\n",
    "    # Apply the log transformation to the specific feature in your training data\n",
    "    small_constant = 1e-10  # You can adjust this constant as needed\n",
    "    # df['LogColumn'] = np.log(df['OriginalColumn'] + small_constant)\n",
    "    data['Log_DisbursementGross'] = np.log1p(data['DisbursementGross'])\n",
    "    data['Log_GrAppv'] = np.log1p(data['GrAppv'])\n",
    "    data['Log_SBA_Appv'] = np.log1p(data['SBA_Appv'])\n",
    "    data['Log_BalanceGross'] = np.log1p(data['BalanceGross'])\n",
    "    data['TotalJobs'] = data['CreateJob'] + data['RetainedJob']\n",
    "    #train_encoded['Loan_Efficiency'] = train_encoded['DisbursementGross'] / (train_encoded['CreateJob'] + train_encoded['RetainedJob'] + 1)\n",
    "    # Calculate 'LoanToIncomeRatio' as a ratio of 'SBA_Appv' to 'DisbursementGross'\n",
    "    data['IncomeToLoanRatio'] = data['DisbursementGross'] / data['SBA_Appv']\n",
    "    # Calculate 'LoanToEmployeesRatio' as a ratio of 'SBA_Appv' to 'NoEmp'\n",
    "    data['EmployeesToLoanRatio'] = data['NoEmp'] / data['SBA_Appv']\n",
    "    # Create a binary feature to indicate loans with a balance ('BalanceGross' > 0)\n",
    "    #train_encoded['HasBalance'] = (train_encoded['BalanceGross'] > 0).astype(int)\n",
    "    # Calculate 'LoanPerJob' as a ratio of 'SBA_Appv' to 'TotalJobs'\n",
    "    data['JobPerLoan'] = data['TotalJobs'] / data['SBA_Appv'] \n",
    "    # Calculate SBA's Gaurenteed Portion of Approved Loan\n",
    "    data['Gauren_SBA_Appv'] = data['GrAppv'] / data['SBA_Appv']\n",
    "\n",
    "\n",
    "    # Scaling the numerical columns\n",
    "    data[numerical_columns] = scaler.transform(data[numerical_columns])                             \n",
    "    \n",
    "    # Target encoding the categorical columns\n",
    "    data_encoded = te.transform(data[te_columns])\n",
    "    data_encoded = data_encoded.add_suffix('_trg')\n",
    "    data_encoded = pd.concat([data_encoded, data], axis=1)\n",
    "    \n",
    "    # Renaming the columns\n",
    "    \n",
    "    for column in te_columns:\n",
    "        data_encoded[column + \"_trg\"].fillna(data_encoded[column + \"_trg\"].mean(), inplace=True)\n",
    "    \n",
    "    # Predicting the probabilities\n",
    "    y_prob = clf.predict_proba(data_encoded[columns_to_score])\n",
    "    y_pred = (y_prob[:,0] < threshold).astype(int)\n",
    "    d = {\n",
    "        \"index\": data.index,\n",
    "        \"label\": y_pred,\n",
    "        \"probability_0\": y_prob[:,0],\n",
    "        \"probability_1\": y_prob[:,1],\n",
    "        \"threshold\":threshold\n",
    "    }\n",
    "    #print(y_prob)\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         index  label  probability_0  probability_1  threshold\n",
      "0            0      1       0.500004       0.499996   0.505051\n",
      "1            1      0       0.639739       0.360261   0.505051\n",
      "2            2      1       0.500004       0.499996   0.505051\n",
      "3            3      0       0.789032       0.210968   0.505051\n",
      "4            4      0       0.878069       0.121931   0.505051\n",
      "...        ...    ...            ...            ...        ...\n",
      "160046  160046      1       0.500004       0.499996   0.505051\n",
      "160047  160047      0       0.745296       0.254704   0.505051\n",
      "160048  160048      0       0.749889       0.250111   0.505051\n",
      "160049  160049      1       0.500004       0.499996   0.505051\n",
      "160050  160050      0       0.641459       0.358541   0.505051\n",
      "\n",
      "[160051 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(scoring(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-fall-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
