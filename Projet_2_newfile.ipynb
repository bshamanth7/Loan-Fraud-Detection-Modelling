{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Extend cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Work/Gre/UTD/Courses/Fall/MIS6341/Softwares/Python/ml-fall-2023/Project2/SBA_loans_project_2.csv\")\n",
    "df.drop(columns=\"index\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>10003</td>\n",
       "      <td>JPMORGAN CHASE BANK NATL ASSOC</td>\n",
       "      <td>IL</td>\n",
       "      <td>561439</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAWTUCKET</td>\n",
       "      <td>RI</td>\n",
       "      <td>2860</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>541810</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISSAQUAH</td>\n",
       "      <td>WA</td>\n",
       "      <td>98027</td>\n",
       "      <td>FIRST-CITIZENS BK &amp; TR CO</td>\n",
       "      <td>WA</td>\n",
       "      <td>448210</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HURST</td>\n",
       "      <td>TX</td>\n",
       "      <td>76053</td>\n",
       "      <td>WILSHIRE BANK</td>\n",
       "      <td>CA</td>\n",
       "      <td>722213</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALPINE</td>\n",
       "      <td>CA</td>\n",
       "      <td>91901</td>\n",
       "      <td>CALIFORNIA BANK &amp; TRUST</td>\n",
       "      <td>CA</td>\n",
       "      <td>233210</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>Kenmore</td>\n",
       "      <td>NY</td>\n",
       "      <td>14217</td>\n",
       "      <td>KEYBANK NATIONAL ASSOCIATION</td>\n",
       "      <td>OH</td>\n",
       "      <td>561720</td>\n",
       "      <td>112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>22750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>MENOMONEE FALLS</td>\n",
       "      <td>WI</td>\n",
       "      <td>53051</td>\n",
       "      <td>WAUKESHA STATE BANK</td>\n",
       "      <td>WI</td>\n",
       "      <td>337110</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>412500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>LONGVIEW</td>\n",
       "      <td>TX</td>\n",
       "      <td>75604</td>\n",
       "      <td>CAPITAL ONE NATL ASSOC</td>\n",
       "      <td>VA</td>\n",
       "      <td>517310</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>128800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>114750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>CAMDEN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>8105</td>\n",
       "      <td>BANK OF AMERICA NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>447110</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>COVENTRY</td>\n",
       "      <td>RI</td>\n",
       "      <td>2816</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>541511</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   City State    Zip                            Bank  \\\n",
       "0              NEW YORK    NY  10003  JPMORGAN CHASE BANK NATL ASSOC   \n",
       "1             PAWTUCKET    RI   2860        CITIZENS BANK NATL ASSOC   \n",
       "2              ISSAQUAH    WA  98027       FIRST-CITIZENS BK & TR CO   \n",
       "3                 HURST    TX  76053                   WILSHIRE BANK   \n",
       "4                ALPINE    CA  91901         CALIFORNIA BANK & TRUST   \n",
       "...                 ...   ...    ...                             ...   \n",
       "800250          Kenmore    NY  14217    KEYBANK NATIONAL ASSOCIATION   \n",
       "800251  MENOMONEE FALLS    WI  53051             WAUKESHA STATE BANK   \n",
       "800252         LONGVIEW    TX  75604          CAPITAL ONE NATL ASSOC   \n",
       "800253           CAMDEN    NJ   8105      BANK OF AMERICA NATL ASSOC   \n",
       "800254         COVENTRY    RI   2816        CITIZENS BANK NATL ASSOC   \n",
       "\n",
       "       BankState   NAICS  NoEmp  NewExist  CreateJob  RetainedJob  \\\n",
       "0             IL  561439      9       1.0          1            9   \n",
       "1             RI  541810      8       1.0          4           12   \n",
       "2             WA  448210      9       2.0          0            0   \n",
       "3             CA  722213      4       1.0          0            4   \n",
       "4             CA  233210      1       1.0          0            1   \n",
       "...          ...     ...    ...       ...        ...          ...   \n",
       "800250        OH  561720    112       1.0          0            0   \n",
       "800251        WI  337110     75       1.0          0           75   \n",
       "800252        VA  517310      2       1.0          0            0   \n",
       "800253        RI  447110      4       2.0          0            0   \n",
       "800254        RI  541511      1       1.0          0            1   \n",
       "\n",
       "        FranchiseCode  UrbanRural RevLineCr LowDoc  DisbursementGross  \\\n",
       "0                   1           1         0      N            68000.0   \n",
       "1                   0           1         N      N            90000.0   \n",
       "2                   1           0         N      N           450000.0   \n",
       "3                   1           1         0      N           140000.0   \n",
       "4                   1           2         Y      N            50000.0   \n",
       "...               ...         ...       ...    ...                ...   \n",
       "800250              1           1         N      N            45500.0   \n",
       "800251              1           1         0      N           550000.0   \n",
       "800252              1           1         0      Y           128800.0   \n",
       "800253              1           1         Y      N           100000.0   \n",
       "800254              0           1         N      N            10000.0   \n",
       "\n",
       "        BalanceGross    GrAppv  SBA_Appv  MIS_Status  \n",
       "0                0.0   68000.0   34000.0           0  \n",
       "1                0.0   90000.0   45000.0           1  \n",
       "2                0.0  450000.0  337500.0           0  \n",
       "3                0.0  165000.0   82500.0           0  \n",
       "4                0.0   50000.0   25000.0           0  \n",
       "...              ...       ...       ...         ...  \n",
       "800250           0.0   45500.0   22750.0           0  \n",
       "800251           0.0  550000.0  412500.0           0  \n",
       "800252           0.0  135000.0  114750.0           0  \n",
       "800253           0.0  100000.0   50000.0           0  \n",
       "800254           0.0   10000.0    5000.0           0  \n",
       "\n",
       "[800255 rows x 19 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                   26\n",
       "State                  13\n",
       "Zip                     0\n",
       "Bank                 1381\n",
       "BankState            1386\n",
       "NAICS                   0\n",
       "NoEmp                   0\n",
       "NewExist              127\n",
       "CreateJob               0\n",
       "RetainedJob             0\n",
       "FranchiseCode           0\n",
       "UrbanRural              0\n",
       "RevLineCr            4016\n",
       "LowDoc               2316\n",
       "DisbursementGross       0\n",
       "BalanceGross            0\n",
       "GrAppv                  0\n",
       "SBA_Appv                0\n",
       "MIS_Status              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City unique values are ['NEW YORK' 'PAWTUCKET' 'ISSAQUAH' ... 'ST  FRANCIS' 'Stevens point'\n",
      " 'Pylesville']\n",
      "\n",
      "\n",
      "City data type is object\n",
      "State unique values are ['NY' 'RI' 'WA' 'TX' 'CA' 'NC' 'MN' 'MO' 'FL' 'IA' 'IL' 'DC' 'PA' 'AL'\n",
      " 'MS' 'OH' 'MA' 'NJ' 'ME' 'NV' 'LA' 'MI' 'IN' 'GA' 'UT' 'VA' 'WI' 'TN'\n",
      " 'KS' 'NH' 'CO' 'CT' 'KY' 'AZ' 'ID' 'DE' 'SD' 'AR' 'MD' 'OK' 'SC' 'NM'\n",
      " 'MT' 'NE' 'OR' 'WY' 'AK' 'HI' 'VT' 'ND' 'WV' nan]\n",
      "\n",
      "\n",
      "State data type is object\n",
      "Zip unique values are [10003  2860 98027 ... 78944 17814 95812]\n",
      "\n",
      "\n",
      "Zip data type is int64\n",
      "Bank unique values are ['JPMORGAN CHASE BANK NATL ASSOC' 'CITIZENS BANK NATL ASSOC'\n",
      " 'FIRST-CITIZENS BK & TR CO' ... 'TULSA NATIONAL BANCSHARES, INC'\n",
      " 'BEACH PLAZA LLC' 'THE LEADERS BANK']\n",
      "\n",
      "\n",
      "Bank data type is object\n",
      "BankState unique values are ['IL' 'RI' 'WA' 'CA' 'NC' 'MN' 'MO' 'OR' 'FL' 'IA' 'SD' 'DC' 'TX' 'PA'\n",
      " 'VA' 'AL' 'OH' 'MS' 'IN' 'MA' 'ME' 'MI' 'DE' 'UT' 'SC' 'NY' 'KS' 'CO'\n",
      " 'LA' 'WI' 'CT' 'AZ' 'AR' 'MD' 'OK' 'NM' 'ID' 'MT' 'NJ' 'KY' 'NE' 'WY'\n",
      " 'GA' 'HI' 'NH' 'VT' 'ND' 'TN' nan 'NV' 'AK' 'WV' 'PR' 'EN' 'GU']\n",
      "\n",
      "\n",
      "BankState data type is object\n",
      "NAICS unique values are [561439 541810 448210 ... 922140 221114 333241]\n",
      "\n",
      "\n",
      "NAICS data type is int64\n",
      "NoEmp unique values are [   9    8    4    1    3   25   10    2   12    6   21   15   19    7\n",
      "   70   45   14   57   30   16   13   35    5   17   11   42   33   36\n",
      "    0   65   20   23  175   18   50   34   60   26   80   40   22   24\n",
      "   31  300   55   29   44   76 3030   75   32   28   41  135   52  100\n",
      "   90   51   37  350   46  207   27   64  160   98   92  190   38   47\n",
      "   39   62   85  985  150   48   79   72  387   84   69 9945   49   68\n",
      "  124   43   73  200  140   59  120  174   54   71  101  102   56 5000\n",
      "  142   67  195  185   53  145  435  110  109  115  425  281   58  153\n",
      "   95   63   61  750  133   81   74   83   82  700  111  132  114   93\n",
      "   78  146   89   77  170  250  205  125  130  184   94  105   97   99\n",
      "   86  104  158  220  155  163  247  246  137  106  450  113  151   96\n",
      "  500  116 1000  118  280  141 5149   66  126   88  400  188  108  154\n",
      "  223  325  900  127  189  222  360   91  107  498  131   87  230  421\n",
      "  162  218  515  180  271  138  128  122  386  179  345  129  165  240\n",
      "  117 3400 1644  315  182  134  123  112  275  139  210  232  260  288\n",
      " 6000  245  119  215 1150  600  258  227  261  206  257 1382  270  203\n",
      "  256  499  144  285  161  295 1400  375  608 1010 1500  177 1200  103\n",
      "  173 4000  121 1700  314  340  192  307  147  329  339 1451 8041  226\n",
      " 1003  225  231  254  148  344  191  712  967  149  187  403  152  520\n",
      " 2202  420  299  351 1524  212  136  156  166 7231  323 5921  208  290\n",
      "  202 7538 5812  143  197  213  550  310  305 3900 1112  233  761  241\n",
      "  521  228 3200 2200  317  249 2000  346  243  178  840  167  475  172\n",
      "  248 3000 1515 1800  330  237 1461  214  625  740  186  211 2151  204\n",
      "  255  217 2400 5680  196 1005 7389  306  171 5211  265  168  157  327\n",
      " 1100  427  390 2401  394  236 3100  216  289  458  850  176 1600 8000\n",
      "  169  221  720 2501  760  430  384 1981  253 2725  234  277  510  194\n",
      "  224  263  463  259 9090 3737  268  365  488  283  278  342  332  404\n",
      "  484  423  198 1940  318 3713  530  235  433  273  353 4100  455  304\n",
      "  382  276  267  424  193  640  606  456 3089  164  407  336  362 1706\n",
      "  585  560  252  355  576 4685  308  251  320  396 7212  442  380 3500\n",
      "  385  808 1300  183  376 4005  605  454  312  209  505 9999 1233 1711\n",
      "  181 5947  523  479 7000  279  301  262 3334  358 2300 2100  448  602\n",
      "  713 7941  413  780 4012  635  302 2020  685 2120  575  294  540  238\n",
      "  369  405  313 2510 1900 5555 1020  395 4847  377  525  445 2610  401\n",
      "  354  322 7241 2500 5013  287 3009  242  266  465  688 2700 4658 1073\n",
      " 1340  717  410  229  269 5200  282 9992 1520 1235  274  480  485 1980\n",
      " 1050  296  383  426  408 1920 6501 7216  544  298  368  782  476  324\n",
      " 1629 1550  609  363  680 1542  827 7111  357 1012 2232  800 1101  464\n",
      "  447  735  284 2010  341 5084  828  495  370  538  319 7991 1603 7999\n",
      " 3732 8018 2121  199  535  244 1250 1280 9000  292 1145  293 2520  650\n",
      "  356  159 1030 4800 7007  328 4300 3170  570  660  414  441  429  823\n",
      "  367  348  858]\n",
      "\n",
      "\n",
      "NoEmp data type is int64\n",
      "NewExist unique values are [ 1.  2.  0. nan]\n",
      "\n",
      "\n",
      "NewExist data type is float64\n",
      "CreateJob unique values are [   1    4    0   15    3    6    8    9    2   20    7   10   12    5\n",
      "   26   35   30   13   23   11   45   40   65   29   25   16   46   21\n",
      "  458   14   73   70 8800   43  120   38   28   22   49   41   59   33\n",
      "   80   19   17   48   60   50  250   24   18  150   37   57  100   31\n",
      "   44   39   32   79   96   89  118   27   75  451   71  450   85   42\n",
      "   36  456   52  105  135  125  452  200  300   54   63   61   90   34\n",
      "  154   64   47   76   82  171   56  175  256   55  198   58  110  138\n",
      " 3000  264   98  158   69   95  162   68  124   66  119  860   72   92\n",
      "  115   83  168  206   78  116   62  500   53   67   84  255  600   51\n",
      "  400  137  104  130  152  140  454  226   77  453  225   97  270  123\n",
      "  126 3100  240  108  160  102 1530  235   99  189  114   87  106  165\n",
      "  112  179  101   88  141  167  183  131   81  455   94  433  205  136\n",
      " 1618 1100  223  146  457 5199 1000   74 3500  121  409  750  220 1711\n",
      " 5085  148  155  184 1027 2515  186  280 5621 1016  145  310  129  360\n",
      "  386   86  375  169  109  170   93  182  397  195  365  180  128  190\n",
      " 1011  221  103  350  157  174  222  127  149 1150  480  363 2140  214\n",
      "  252  569 2020  320  144  164  153 1118  139  151  163  210]\n",
      "\n",
      "\n",
      "CreateJob data type is int64\n",
      "RetainedJob unique values are [   9   12    0    4    1   40   10    2    6    8    5   20   30   13\n",
      "   35   11    3   14   19    7   34   21   23   18   50   22   85   80\n",
      "   60   45   15  330   25   65   33   29   17   16   44   32   31   28\n",
      "   41   27   90   24  207  160   92  190   38   46 8800   26   48   72\n",
      "   84   36   70  200  140  120   54   52   71   53   47  102   55   75\n",
      "  150  142   37   43   64  300  117   42   95   39  281   49   58   96\n",
      "  212  100   63   79   82   57  111   69   62  135  250   61   56  155\n",
      "   78  104  158   67  163  270  350  151  500  116   51  118  275  141\n",
      "  450  126   74   86  223  387   76  498  189   87  130  115   59  145\n",
      "  205  175  125  256  138  105   93  137  164  180  219  139   77  110\n",
      "   68   81  103  210  109  167  230   83   99  162  185  171   91   97\n",
      "  119  304  101   98  107  285  240  257  170   73  165  229  161  149\n",
      "  173  750  113  231  114  168  156  362  967   88  128  122  127   89\n",
      "  220  129  251  404  375   66  203  550  267  177  133  123  263  143\n",
      "   94 3900  182  121 1300  384 2200  254  900  243  112  178  310  226\n",
      "  184  237  515  146  154  192  265  157  327  245  108  400  194  172\n",
      "  169  134  186  153  216  106  152 4441  360  124  259  187  131  202\n",
      "  316  600  472  371  278  342  206  214  484  204  390  318  225 3225\n",
      "  286 1700  428  176  147  497  268  585  312  393  148  280  290  475\n",
      "  235  291  320  369  132 1711  197  523  195  144  448  602  217 3100\n",
      "  302  136  685  540  295  215  366  322  287  315  485  266  610  292\n",
      "  476  208  430  410  247  191 1600  420  325 4000  233  188 5000  355\n",
      "  196  260  274  480  544  298  262  609  363  199  815  277  403  166\n",
      " 7250  720  370  548 3200  911  183  221 1500 1000  675  535  232  236\n",
      "  198  159  255  252  356  394 1111  201 9500  328  297  660  700  317]\n",
      "\n",
      "\n",
      "RetainedJob data type is int64\n",
      "FranchiseCode unique values are [    1     0 78760 ... 21424 41418 29580]\n",
      "\n",
      "\n",
      "FranchiseCode data type is int64\n",
      "UrbanRural unique values are [1 0 2]\n",
      "\n",
      "\n",
      "UrbanRural data type is int64\n",
      "RevLineCr unique values are ['0' 'N' 'Y' 'T' nan '1' 'A' '`' '4' 'R' '2' '.' '5' 'C' ',' '-' 'Q' '7'\n",
      " '3']\n",
      "\n",
      "\n",
      "RevLineCr data type is object\n",
      "LowDoc unique values are ['N' 'Y' '0' nan 'C' 'A' 'S' 'R' '1']\n",
      "\n",
      "\n",
      "LowDoc data type is object\n",
      "DisbursementGross unique values are [ 68000.  90000. 450000. ... 199123.  67516.  97203.]\n",
      "\n",
      "\n",
      "DisbursementGross data type is float64\n",
      "BalanceGross unique values are [0.00000e+00 4.15090e+04 3.95476e+05 9.11100e+03 8.46170e+04 8.27875e+05\n",
      " 1.27500e+04 9.96262e+05 9.69080e+04 2.50000e+04 1.15820e+05 1.76000e+03\n",
      " 3.71000e+04 6.00000e+02 4.31270e+04]\n",
      "\n",
      "\n",
      "BalanceGross data type is float64\n",
      "GrAppv unique values are [  68000.   90000.  450000. ... 1853900.   32916.   35224.]\n",
      "\n",
      "\n",
      "GrAppv data type is float64\n",
      "SBA_Appv unique values are [  34000.   45000.  337500. ...   26333. 1609000.   17612.]\n",
      "\n",
      "\n",
      "SBA_Appv data type is float64\n",
      "MIS_Status unique values are [0 1]\n",
      "\n",
      "\n",
      "MIS_Status data type is int64\n"
     ]
    }
   ],
   "source": [
    "#show unique values in each column and its data type\n",
    "for col in df.columns:\n",
    "    print(f'{col} unique values are {df[col].unique()}')\n",
    "    print(\"\\n\")\n",
    "    print(f'{col} data type is {df[col].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>10003</td>\n",
       "      <td>JPMORGAN CHASE BANK NATL ASSOC</td>\n",
       "      <td>IL</td>\n",
       "      <td>561439</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAWTUCKET</td>\n",
       "      <td>RI</td>\n",
       "      <td>2860</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>541810</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISSAQUAH</td>\n",
       "      <td>WA</td>\n",
       "      <td>98027</td>\n",
       "      <td>FIRST-CITIZENS BK &amp; TR CO</td>\n",
       "      <td>WA</td>\n",
       "      <td>448210</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HURST</td>\n",
       "      <td>TX</td>\n",
       "      <td>76053</td>\n",
       "      <td>WILSHIRE BANK</td>\n",
       "      <td>CA</td>\n",
       "      <td>722213</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALPINE</td>\n",
       "      <td>CA</td>\n",
       "      <td>91901</td>\n",
       "      <td>CALIFORNIA BANK &amp; TRUST</td>\n",
       "      <td>CA</td>\n",
       "      <td>233210</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800250</th>\n",
       "      <td>Kenmore</td>\n",
       "      <td>NY</td>\n",
       "      <td>14217</td>\n",
       "      <td>KEYBANK NATIONAL ASSOCIATION</td>\n",
       "      <td>OH</td>\n",
       "      <td>561720</td>\n",
       "      <td>112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>22750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800251</th>\n",
       "      <td>MENOMONEE FALLS</td>\n",
       "      <td>WI</td>\n",
       "      <td>53051</td>\n",
       "      <td>WAUKESHA STATE BANK</td>\n",
       "      <td>WI</td>\n",
       "      <td>337110</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>412500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800252</th>\n",
       "      <td>LONGVIEW</td>\n",
       "      <td>TX</td>\n",
       "      <td>75604</td>\n",
       "      <td>CAPITAL ONE NATL ASSOC</td>\n",
       "      <td>VA</td>\n",
       "      <td>517310</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>128800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>114750.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800253</th>\n",
       "      <td>CAMDEN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>8105</td>\n",
       "      <td>BANK OF AMERICA NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>447110</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800254</th>\n",
       "      <td>COVENTRY</td>\n",
       "      <td>RI</td>\n",
       "      <td>2816</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>541511</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800255 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   City State    Zip                            Bank  \\\n",
       "0              NEW YORK    NY  10003  JPMORGAN CHASE BANK NATL ASSOC   \n",
       "1             PAWTUCKET    RI   2860        CITIZENS BANK NATL ASSOC   \n",
       "2              ISSAQUAH    WA  98027       FIRST-CITIZENS BK & TR CO   \n",
       "3                 HURST    TX  76053                   WILSHIRE BANK   \n",
       "4                ALPINE    CA  91901         CALIFORNIA BANK & TRUST   \n",
       "...                 ...   ...    ...                             ...   \n",
       "800250          Kenmore    NY  14217    KEYBANK NATIONAL ASSOCIATION   \n",
       "800251  MENOMONEE FALLS    WI  53051             WAUKESHA STATE BANK   \n",
       "800252         LONGVIEW    TX  75604          CAPITAL ONE NATL ASSOC   \n",
       "800253           CAMDEN    NJ   8105      BANK OF AMERICA NATL ASSOC   \n",
       "800254         COVENTRY    RI   2816        CITIZENS BANK NATL ASSOC   \n",
       "\n",
       "       BankState   NAICS  NoEmp  NewExist  CreateJob  RetainedJob  \\\n",
       "0             IL  561439      9       1.0          1            9   \n",
       "1             RI  541810      8       1.0          4           12   \n",
       "2             WA  448210      9       2.0          0            0   \n",
       "3             CA  722213      4       1.0          0            4   \n",
       "4             CA  233210      1       1.0          0            1   \n",
       "...          ...     ...    ...       ...        ...          ...   \n",
       "800250        OH  561720    112       1.0          0            0   \n",
       "800251        WI  337110     75       1.0          0           75   \n",
       "800252        VA  517310      2       1.0          0            0   \n",
       "800253        RI  447110      4       2.0          0            0   \n",
       "800254        RI  541511      1       1.0          0            1   \n",
       "\n",
       "        FranchiseCode  UrbanRural RevLineCr LowDoc  DisbursementGross  \\\n",
       "0                   1           1         0      N            68000.0   \n",
       "1                   0           1         N      N            90000.0   \n",
       "2                   1           0         N      N           450000.0   \n",
       "3                   1           1         0      N           140000.0   \n",
       "4                   1           2         Y      N            50000.0   \n",
       "...               ...         ...       ...    ...                ...   \n",
       "800250              1           1         N      N            45500.0   \n",
       "800251              1           1         0      N           550000.0   \n",
       "800252              1           1         0      Y           128800.0   \n",
       "800253              1           1         Y      N           100000.0   \n",
       "800254              0           1         N      N            10000.0   \n",
       "\n",
       "        BalanceGross    GrAppv  SBA_Appv  MIS_Status  \n",
       "0                0.0   68000.0   34000.0           0  \n",
       "1                0.0   90000.0   45000.0           1  \n",
       "2                0.0  450000.0  337500.0           0  \n",
       "3                0.0  165000.0   82500.0           0  \n",
       "4                0.0   50000.0   25000.0           0  \n",
       "...              ...       ...       ...         ...  \n",
       "800250           0.0   45500.0   22750.0           0  \n",
       "800251           0.0  550000.0  412500.0           0  \n",
       "800252           0.0  135000.0  114750.0           0  \n",
       "800253           0.0  100000.0   50000.0           0  \n",
       "800254           0.0   10000.0    5000.0           0  \n",
       "\n",
       "[800255 rows x 19 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevLineCr ['N' 'Y']\n",
      "LowDoc ['N' 'Y']\n",
      "NewExist [1.0 2.0 None]\n"
     ]
    }
   ],
   "source": [
    "for i in df['RevLineCr']:\n",
    "    if i not in ['Y','N']:\n",
    "        df['RevLineCr'].replace(i,'N',inplace=True)\n",
    "print(\"RevLineCr\",df['RevLineCr'].unique())\n",
    "\n",
    "for i in df['LowDoc']:\n",
    "    if i not in ['Y','N']:\n",
    "        df['LowDoc'].replace(i,'N',inplace=True)\n",
    "print(\"LowDoc\",df['LowDoc'].unique())\n",
    "\n",
    "for i in df['NewExist']:\n",
    "    if i not in [1,2]:\n",
    "        df['NewExist'].replace(i,None,inplace=True)\n",
    "print(\"NewExist\",df['NewExist'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                   26\n",
       "State                  13\n",
       "Zip                     0\n",
       "Bank                 1381\n",
       "BankState            1386\n",
       "NAICS                   0\n",
       "NoEmp                   0\n",
       "NewExist             1057\n",
       "CreateJob               0\n",
       "RetainedJob             0\n",
       "FranchiseCode           0\n",
       "UrbanRural              0\n",
       "RevLineCr               0\n",
       "LowDoc                  0\n",
       "DisbursementGross       0\n",
       "BalanceGross            0\n",
       "GrAppv                  0\n",
       "SBA_Appv                0\n",
       "MIS_Status              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols=['City', 'State', 'Bank', 'BankState', 'RevLineCr', 'LowDoc','NewExist']\n",
    "for column in category_cols:\n",
    "  df[column]=df[column].fillna(df[column].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                 0\n",
       "State                0\n",
       "Zip                  0\n",
       "Bank                 0\n",
       "BankState            0\n",
       "NAICS                0\n",
       "NoEmp                0\n",
       "NewExist             0\n",
       "CreateJob            0\n",
       "RetainedJob          0\n",
       "FranchiseCode        0\n",
       "UrbanRural           0\n",
       "RevLineCr            0\n",
       "LowDoc               0\n",
       "DisbursementGross    0\n",
       "BalanceGross         0\n",
       "GrAppv               0\n",
       "SBA_Appv             0\n",
       "MIS_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((560178, 19), (240077, 19))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test = train_test_split(df,test_size=0.3,random_state=123)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Training set has 560178 rows and testing set has 240077 samples\n",
    "\n",
    "Target encoding is a data preprocessing technique used to convert categorical variables into numerical values that can be used by machine learning algorithms. It works by replacing each category with the average value of the target variable for that category. This can be helpful for algorithms that cannot handle categorical variables directly.\n",
    "\n",
    "In this case the target variable is \"MIS_Status\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148172</th>\n",
       "      <td>0.215946</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>45648</td>\n",
       "      <td>0.740692</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>452990</td>\n",
       "      <td>2</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>10625.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744579</th>\n",
       "      <td>0.226933</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>43240</td>\n",
       "      <td>0.133135</td>\n",
       "      <td>0.158188</td>\n",
       "      <td>445310</td>\n",
       "      <td>7</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321200</th>\n",
       "      <td>0.252778</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>21037</td>\n",
       "      <td>0.194430</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74901</th>\n",
       "      <td>0.275938</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>90071</td>\n",
       "      <td>0.141177</td>\n",
       "      <td>0.178801</td>\n",
       "      <td>541310</td>\n",
       "      <td>12</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.251879</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>985500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426895</th>\n",
       "      <td>0.057056</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>95037</td>\n",
       "      <td>0.412096</td>\n",
       "      <td>0.380604</td>\n",
       "      <td>561720</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City     State    Zip      Bank  BankState   NAICS  NoEmp  \\\n",
       "148172  0.215946  0.165802  45648  0.740692   0.217642  452990      2   \n",
       "744579  0.226933  0.165802  43240  0.133135   0.158188  445310      7   \n",
       "321200  0.252778  0.196143  21037  0.194430   0.076619       0      3   \n",
       "74901   0.275938  0.184227  90071  0.141177   0.178801  541310     12   \n",
       "426895  0.057056  0.184227  95037  0.412096   0.380604  561720      1   \n",
       "\n",
       "        NewExist  CreateJob  RetainedJob  FranchiseCode  UrbanRural  \\\n",
       "148172   0.17067          2            2              0    0.186517   \n",
       "744579   0.17067          0            0              0    0.243731   \n",
       "321200   0.17067          0            0              1    0.070886   \n",
       "74901    0.17067         12           12              1    0.243731   \n",
       "426895   0.17067          0            1              0    0.243731   \n",
       "\n",
       "        RevLineCr    LowDoc  DisbursementGross  BalanceGross    GrAppv  \\\n",
       "148172   0.152625  0.186815            12500.0           0.0   12500.0   \n",
       "744579   0.152625  0.186815            20000.0           0.0   20000.0   \n",
       "321200   0.152625  0.089154            25000.0           0.0   25000.0   \n",
       "74901    0.251879  0.186815           985500.0           0.0  350000.0   \n",
       "426895   0.152625  0.186815            50000.0           0.0   50000.0   \n",
       "\n",
       "        SBA_Appv  MIS_Status  \n",
       "148172   10625.0           1  \n",
       "744579   10000.0           0  \n",
       "321200   20000.0           0  \n",
       "74901   175000.0           1  \n",
       "426895   25000.0           0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target encoder\n",
    "import category_encoders as ce\n",
    "categorical_columns = ['City', 'State', 'Bank', 'BankState', 'RevLineCr', 'LowDoc','NewExist', 'UrbanRural']\n",
    "\n",
    "encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "encoder.fit(X_train, X_train['MIS_Status'])\n",
    "\n",
    "train_encoded = encoder.transform(X_train)\n",
    "test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Renaming the columns\n",
    "train_encoded.rename(columns={col: col + \"_trg\" if col in categorical_columns else col for col in train_encoded.columns}, inplace=False)\n",
    "test_encoded.rename(columns={col: col + \"_trg\" if col in categorical_columns else col for col in test_encoded.columns}, inplace=False)\n",
    "\n",
    "train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 560178 entries, 148172 to 773630\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   City               560178 non-null  float64\n",
      " 1   State              560178 non-null  float64\n",
      " 2   Zip                560178 non-null  int64  \n",
      " 3   Bank               560178 non-null  float64\n",
      " 4   BankState          560178 non-null  float64\n",
      " 5   NAICS              560178 non-null  int64  \n",
      " 6   NoEmp              560178 non-null  int64  \n",
      " 7   NewExist           560178 non-null  float64\n",
      " 8   CreateJob          560178 non-null  int64  \n",
      " 9   RetainedJob        560178 non-null  int64  \n",
      " 10  FranchiseCode      560178 non-null  int64  \n",
      " 11  UrbanRural         560178 non-null  float64\n",
      " 12  RevLineCr          560178 non-null  float64\n",
      " 13  LowDoc             560178 non-null  float64\n",
      " 14  DisbursementGross  560178 non-null  float64\n",
      " 15  BalanceGross       560178 non-null  float64\n",
      " 16  GrAppv             560178 non-null  float64\n",
      " 17  SBA_Appv           560178 non-null  float64\n",
      " 18  MIS_Status         560178 non-null  int64  \n",
      "dtypes: float64(12), int64(7)\n",
      "memory usage: 85.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler in scikit-learn is a preprocessing technique that centers and scales numerical features such that they have a mean of zero and a standard deviation of one.\n",
    "\n",
    "We will make use of the StandardScaler, which is used to transform both the training and test data in the same way, ensuring that the features have the same mean and standard deviation in both datasets.\n",
    "\n",
    "Here we will scale it on the training set and transform on both training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148172</th>\n",
       "      <td>0.215946</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>45648</td>\n",
       "      <td>0.740692</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>452990</td>\n",
       "      <td>-0.123748</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.026808</td>\n",
       "      <td>-0.036871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.654946</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.635102</td>\n",
       "      <td>-0.606817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744579</th>\n",
       "      <td>0.226933</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>43240</td>\n",
       "      <td>0.133135</td>\n",
       "      <td>0.158188</td>\n",
       "      <td>445310</td>\n",
       "      <td>-0.058247</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.628851</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.608622</td>\n",
       "      <td>-0.609553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321200</th>\n",
       "      <td>0.252778</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>21037</td>\n",
       "      <td>0.194430</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.110648</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>-0.611454</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.590969</td>\n",
       "      <td>-0.565780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74901</th>\n",
       "      <td>0.275938</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>90071</td>\n",
       "      <td>0.141177</td>\n",
       "      <td>0.178801</td>\n",
       "      <td>541310</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.251879</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>2.730474</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>0.556485</td>\n",
       "      <td>0.112702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426895</th>\n",
       "      <td>0.057056</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>95037</td>\n",
       "      <td>0.412096</td>\n",
       "      <td>0.380604</td>\n",
       "      <td>561720</td>\n",
       "      <td>-0.136849</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.041138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.524470</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.502703</td>\n",
       "      <td>-0.543894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City     State    Zip      Bank  BankState   NAICS     NoEmp  \\\n",
       "148172  0.215946  0.165802  45648  0.740692   0.217642  452990 -0.123748   \n",
       "744579  0.226933  0.165802  43240  0.133135   0.158188  445310 -0.058247   \n",
       "321200  0.252778  0.196143  21037  0.194430   0.076619       0 -0.110648   \n",
       "74901   0.275938  0.184227  90071  0.141177   0.178801  541310  0.007255   \n",
       "426895  0.057056  0.184227  95037  0.412096   0.380604  561720 -0.136849   \n",
       "\n",
       "        NewExist  CreateJob  RetainedJob  FranchiseCode  UrbanRural  \\\n",
       "148172   0.17067  -0.026808    -0.036871              0    0.186517   \n",
       "744579   0.17067  -0.035352    -0.045405              0    0.243731   \n",
       "321200   0.17067  -0.035352    -0.045405              1    0.070886   \n",
       "74901    0.17067   0.015917     0.005801              1    0.243731   \n",
       "426895   0.17067  -0.035352    -0.041138              0    0.243731   \n",
       "\n",
       "        RevLineCr    LowDoc  DisbursementGross  BalanceGross    GrAppv  \\\n",
       "148172   0.152625  0.186815          -0.654946     -0.002095 -0.635102   \n",
       "744579   0.152625  0.186815          -0.628851     -0.002095 -0.608622   \n",
       "321200   0.152625  0.089154          -0.611454     -0.002095 -0.590969   \n",
       "74901    0.251879  0.186815           2.730474     -0.002095  0.556485   \n",
       "426895   0.152625  0.186815          -0.524470     -0.002095 -0.502703   \n",
       "\n",
       "        SBA_Appv  MIS_Status  \n",
       "148172 -0.606817           1  \n",
       "744579 -0.609553           0  \n",
       "321200 -0.565780           0  \n",
       "74901   0.112702           1  \n",
       "426895 -0.543894           0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from copy import deepcopy\n",
    "\n",
    "numerical_columns = [ 'NoEmp', 'CreateJob', 'RetainedJob', 'GrAppv', 'SBA_Appv', 'DisbursementGross', 'BalanceGross']\n",
    "scaler = StandardScaler()\n",
    "train_encoded[numerical_columns] = scaler.fit_transform(train_encoded[numerical_columns])\n",
    "test_encoded[numerical_columns] = scaler.transform(test_encoded[numerical_columns])\n",
    "\n",
    "train_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created Feature extraction by making use of old variables in the following way\n",
    "\n",
    "\n",
    "(1) Log_Disbursement which gives the natural logarithmic form of DisbursementGross variable\n",
    "\n",
    "(2) Log_GrAppv the logarithmic version of the approved loan amount by the bank\n",
    "\n",
    "(3) Log_SBA_Appv, the logarithmic amount of the approved loan that will be assisted by SBA \n",
    "\n",
    "(4) Log_BalanceGross, is the logarithmic amount of total amount in an account or the total value of a financial asset or liability before any deductions or adjustments are made.\n",
    "\n",
    "(5) TotalJobs variable which is an addition of Createjobs(New people recruited) and RetainedJob (workers working before)\n",
    "\n",
    "(6) IncomeToLoan its values are calculated by dividing the 'DisbursementGross' column by the 'SBA_Appv' column for each corresponding row. This ratio can help you analyze the relationship between the amount disbursed and the approved SBA loan amount in terms of income.\n",
    "\n",
    "(7)  EmployeesToLoanRatio, its values are calculated by dividing the 'NoEmp' column (number of employees) by the 'SBA_Appv' column (approved SBA loan amount) for each corresponding row. This ratio can help you analyze the relationship between the number of employees and the size of the SBA loan approved for each entry in the dataset.\n",
    "\n",
    "(8) JobPerLoan, its values are calculated by dividing the 'TotalJobs' column (representing the total number of jobs) by the 'SBA_Appv' column (approved SBA loan amount) for each corresponding row. This ratio can help you analyze the impact of the SBA loan on job creation or support, expressed as the number of jobs per unit of loan amount approved.\n",
    "\n",
    "(9) Gauren_SBA_Appv, Its values are calculated by dividing the 'GrAppv' column (gross amount approved by the lender) by the 'SBA_Appv' column (the approved SBA loan amount) for each corresponding row. This ratio helps you analyze the extent to which the SBA is guaranteeing the loan relative to the total loan amount approved by the lender.\n",
    "\n",
    "(10) DefaultRate, Finally, we create a new feature 'DefaultRate' in the 'train_encoded' DataFrame and set its value to the calculated default rate for the particular group of loans based on the \"MIS_Status\" variable. This feature will represent the percentage of loans in the group that are classified as defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Features\n",
    "import numpy as np\n",
    "# Apply the log transformation to the specific feature in your training data\n",
    "#small_constant = 1e-10  # You can adjust this constant as needed\n",
    "# df['LogColumn'] = np.log(df['OriginalColumn'] + small_constant)\n",
    "train_encoded['Log_DisbursementGross'] = np.log1p(train_encoded['DisbursementGross'])\n",
    "train_encoded['Log_GrAppv'] = np.log1p(train_encoded['GrAppv'])\n",
    "train_encoded['Log_SBA_Appv'] = np.log1p(train_encoded['SBA_Appv'])\n",
    "train_encoded['Log_BalanceGross'] = np.log1p(train_encoded['BalanceGross'])\n",
    "train_encoded['TotalJobs'] = train_encoded['CreateJob'] + train_encoded['RetainedJob']\n",
    "#train_encoded['Loan_Efficiency'] = train_encoded['DisbursementGross'] / (train_encoded['CreateJob'] + train_encoded['RetainedJob'] + 1)\n",
    "# Calculate 'LoanToIncomeRatio' as a ratio of 'SBA_Appv' to 'DisbursementGross'\n",
    "train_encoded['IncomeToLoanRatio'] = train_encoded['DisbursementGross'] / train_encoded['SBA_Appv']\n",
    "# Calculate 'LoanToEmployeesRatio' as a ratio of 'SBA_Appv' to 'NoEmp'\n",
    "train_encoded['EmployeesToLoanRatio'] = train_encoded['NoEmp'] / train_encoded['SBA_Appv']\n",
    "# Create a binary feature to indicate loans with a balance ('BalanceGross' > 0)\n",
    "#train_encoded['HasBalance'] = (train_encoded['BalanceGross'] > 0).astype(int)\n",
    "# Calculate 'LoanPerJob' as a ratio of 'SBA_Appv' to 'TotalJobs'\n",
    "train_encoded['JobPerLoan'] = train_encoded['TotalJobs'] / train_encoded['SBA_Appv'] \n",
    "# Calculate SBA's Gaurenteed Portion of Approved Loan\n",
    "train_encoded['Gauren_SBA_Appv'] = train_encoded['GrAppv'] / train_encoded['SBA_Appv']\n",
    "# Filter the DataFrame to include only the relevant rows\n",
    "default_group = train_encoded[train_encoded['MIS_Status'].isin([0, 1])]\n",
    "# Calculate the total number of loans in the filtered group\n",
    "total_loans = len(default_group)\n",
    "# Calculate the number of defaults (CHGOFF) in the filtered group\n",
    "default_loans = len(default_group[default_group['MIS_Status'] == 1])\n",
    "# Calculate the default rate as a percentage\n",
    "default_rate = (default_loans / total_loans) * 100\n",
    "# Create a new feature 'DefaultRate' with the calculated default rate\n",
    "train_encoded['DefaultRate'] = default_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Features\n",
    "import numpy as np\n",
    "# Apply the log transformation to the specific feature in your training data\n",
    "#small_constant = 1e-10  # You can adjust this constant as needed\n",
    "# df['LogColumn'] = np.log(df['OriginalColumn'] + small_constant)\n",
    "test_encoded['Log_DisbursementGross'] = np.log1p(test_encoded['DisbursementGross'])\n",
    "test_encoded['Log_GrAppv'] = np.log1p(test_encoded['GrAppv'])\n",
    "test_encoded['Log_SBA_Appv'] = np.log1p(test_encoded['SBA_Appv'])\n",
    "test_encoded['Log_BalanceGross'] = np.log1p(test_encoded['BalanceGross'])\n",
    "test_encoded['TotalJobs'] = test_encoded['CreateJob'] + test_encoded['RetainedJob']\n",
    "#train_encoded['Loan_Efficiency'] = train_encoded['DisbursementGross'] / (train_encoded['CreateJob'] + train_encoded['RetainedJob'] + 1)\n",
    "# Calculate 'LoanToIncomeRatio' as a ratio of 'SBA_Appv' to 'DisbursementGross'\n",
    "test_encoded['IncomeToLoanRatio'] = test_encoded['DisbursementGross'] / test_encoded['SBA_Appv']\n",
    "# Calculate 'LoanToEmployeesRatio' as a ratio of 'SBA_Appv' to 'NoEmp'\n",
    "test_encoded['EmployeesToLoanRatio'] = test_encoded['NoEmp'] / test_encoded['SBA_Appv']\n",
    "# Create a binary feature to indicate loans with a balance ('BalanceGross' > 0)\n",
    "#train_encoded['HasBalance'] = (train_encoded['BalanceGross'] > 0).astype(int)\n",
    "# Calculate 'LoanPerJob' as a ratio of 'SBA_Appv' to 'TotalJobs'\n",
    "test_encoded['JobPerLoan'] = test_encoded['TotalJobs'] / test_encoded['SBA_Appv'] \n",
    "# Calculate SBA's Gaurenteed Portion of Approved Loan\n",
    "test_encoded['Gauren_SBA_Appv'] = test_encoded['GrAppv'] / test_encoded['SBA_Appv']\n",
    "# Filter the DataFrame to include only the relevant rows\n",
    "default_group = test_encoded[test_encoded['MIS_Status'].isin([0, 1])]\n",
    "# Calculate the total number of loans in the filtered group\n",
    "total_loans = len(default_group)\n",
    "# Calculate the number of defaults (CHGOFF) in the filtered group\n",
    "default_loans = len(default_group[default_group['MIS_Status'] == 1])\n",
    "# Calculate the default rate as a percentage\n",
    "default_rate = (default_loans / total_loans) * 100\n",
    "# Create a new feature 'DefaultRate' with the calculated default rate\n",
    "test_encoded['DefaultRate'] = default_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City', 'State', 'Zip', 'Bank', 'BankState', 'NAICS', 'NoEmp',\n",
       "       'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural',\n",
       "       'RevLineCr', 'LowDoc', 'DisbursementGross', 'BalanceGross', 'GrAppv',\n",
       "       'SBA_Appv', 'MIS_Status', 'Log_DisbursementGross', 'Log_GrAppv',\n",
       "       'Log_SBA_Appv', 'Log_BalanceGross', 'TotalJobs', 'IncomeToLoanRatio',\n",
       "       'EmployeesToLoanRatio', 'JobPerLoan', 'Gauren_SBA_Appv', 'DefaultRate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>Log_DisbursementGross</th>\n",
       "      <th>Log_GrAppv</th>\n",
       "      <th>Log_SBA_Appv</th>\n",
       "      <th>Log_BalanceGross</th>\n",
       "      <th>TotalJobs</th>\n",
       "      <th>IncomeToLoanRatio</th>\n",
       "      <th>EmployeesToLoanRatio</th>\n",
       "      <th>JobPerLoan</th>\n",
       "      <th>Gauren_SBA_Appv</th>\n",
       "      <th>DefaultRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148172</th>\n",
       "      <td>0.215946</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>45648</td>\n",
       "      <td>0.740692</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>452990</td>\n",
       "      <td>-0.123748</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.026808</td>\n",
       "      <td>-0.036871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.654946</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.635102</td>\n",
       "      <td>-0.606817</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.064054</td>\n",
       "      <td>-1.008137</td>\n",
       "      <td>-0.933481</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.063679</td>\n",
       "      <td>1.079313</td>\n",
       "      <td>0.203930</td>\n",
       "      <td>0.104939</td>\n",
       "      <td>1.046611</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744579</th>\n",
       "      <td>0.226933</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>43240</td>\n",
       "      <td>0.133135</td>\n",
       "      <td>0.158188</td>\n",
       "      <td>445310</td>\n",
       "      <td>-0.058247</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.628851</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.608622</td>\n",
       "      <td>-0.609553</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.991151</td>\n",
       "      <td>-0.938082</td>\n",
       "      <td>-0.940463</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>1.031658</td>\n",
       "      <td>0.095556</td>\n",
       "      <td>0.132487</td>\n",
       "      <td>0.998473</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321200</th>\n",
       "      <td>0.252778</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>21037</td>\n",
       "      <td>0.194430</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.110648</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>-0.611454</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.590969</td>\n",
       "      <td>-0.565780</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.945343</td>\n",
       "      <td>-0.893964</td>\n",
       "      <td>-0.834204</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>1.080727</td>\n",
       "      <td>0.195567</td>\n",
       "      <td>0.142737</td>\n",
       "      <td>1.044521</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74901</th>\n",
       "      <td>0.275938</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>90071</td>\n",
       "      <td>0.141177</td>\n",
       "      <td>0.178801</td>\n",
       "      <td>541310</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.251879</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>2.730474</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>0.556485</td>\n",
       "      <td>0.112702</td>\n",
       "      <td>1</td>\n",
       "      <td>1.316535</td>\n",
       "      <td>0.442430</td>\n",
       "      <td>0.106791</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>24.227422</td>\n",
       "      <td>0.064374</td>\n",
       "      <td>0.192698</td>\n",
       "      <td>4.937672</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426895</th>\n",
       "      <td>0.057056</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>95037</td>\n",
       "      <td>0.412096</td>\n",
       "      <td>0.380604</td>\n",
       "      <td>561720</td>\n",
       "      <td>-0.136849</td>\n",
       "      <td>0.17067</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.041138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.524470</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.502703</td>\n",
       "      <td>-0.543894</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.743325</td>\n",
       "      <td>-0.698569</td>\n",
       "      <td>-0.785029</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.076491</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>0.251609</td>\n",
       "      <td>0.140635</td>\n",
       "      <td>0.924268</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City     State    Zip      Bank  BankState   NAICS     NoEmp  \\\n",
       "148172  0.215946  0.165802  45648  0.740692   0.217642  452990 -0.123748   \n",
       "744579  0.226933  0.165802  43240  0.133135   0.158188  445310 -0.058247   \n",
       "321200  0.252778  0.196143  21037  0.194430   0.076619       0 -0.110648   \n",
       "74901   0.275938  0.184227  90071  0.141177   0.178801  541310  0.007255   \n",
       "426895  0.057056  0.184227  95037  0.412096   0.380604  561720 -0.136849   \n",
       "\n",
       "        NewExist  CreateJob  RetainedJob  FranchiseCode  UrbanRural  \\\n",
       "148172   0.17067  -0.026808    -0.036871              0    0.186517   \n",
       "744579   0.17067  -0.035352    -0.045405              0    0.243731   \n",
       "321200   0.17067  -0.035352    -0.045405              1    0.070886   \n",
       "74901    0.17067   0.015917     0.005801              1    0.243731   \n",
       "426895   0.17067  -0.035352    -0.041138              0    0.243731   \n",
       "\n",
       "        RevLineCr    LowDoc  DisbursementGross  BalanceGross    GrAppv  \\\n",
       "148172   0.152625  0.186815          -0.654946     -0.002095 -0.635102   \n",
       "744579   0.152625  0.186815          -0.628851     -0.002095 -0.608622   \n",
       "321200   0.152625  0.089154          -0.611454     -0.002095 -0.590969   \n",
       "74901    0.251879  0.186815           2.730474     -0.002095  0.556485   \n",
       "426895   0.152625  0.186815          -0.524470     -0.002095 -0.502703   \n",
       "\n",
       "        SBA_Appv  MIS_Status  Log_DisbursementGross  Log_GrAppv  Log_SBA_Appv  \\\n",
       "148172 -0.606817           1              -1.064054   -1.008137     -0.933481   \n",
       "744579 -0.609553           0              -0.991151   -0.938082     -0.940463   \n",
       "321200 -0.565780           0              -0.945343   -0.893964     -0.834204   \n",
       "74901   0.112702           1               1.316535    0.442430      0.106791   \n",
       "426895 -0.543894           0              -0.743325   -0.698569     -0.785029   \n",
       "\n",
       "        Log_BalanceGross  TotalJobs  IncomeToLoanRatio  EmployeesToLoanRatio  \\\n",
       "148172         -0.002098  -0.063679           1.079313              0.203930   \n",
       "744579         -0.002098  -0.080758           1.031658              0.095556   \n",
       "321200         -0.002098  -0.080758           1.080727              0.195567   \n",
       "74901          -0.002098   0.021717          24.227422              0.064374   \n",
       "426895         -0.002098  -0.076491           0.964287              0.251609   \n",
       "\n",
       "        JobPerLoan  Gauren_SBA_Appv  DefaultRate  \n",
       "148172    0.104939         1.046611    17.487834  \n",
       "744579    0.132487         0.998473    17.487834  \n",
       "321200    0.142737         1.044521    17.487834  \n",
       "74901     0.192698         4.937672    17.487834  \n",
       "426895    0.140635         0.924268    17.487834  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>Log_DisbursementGross</th>\n",
       "      <th>Log_GrAppv</th>\n",
       "      <th>Log_SBA_Appv</th>\n",
       "      <th>Log_BalanceGross</th>\n",
       "      <th>TotalJobs</th>\n",
       "      <th>IncomeToLoanRatio</th>\n",
       "      <th>EmployeesToLoanRatio</th>\n",
       "      <th>JobPerLoan</th>\n",
       "      <th>Gauren_SBA_Appv</th>\n",
       "      <th>DefaultRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148172</th>\n",
       "      <td>0.215946</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>45648</td>\n",
       "      <td>0.740692</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>452990</td>\n",
       "      <td>-0.123748</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.026808</td>\n",
       "      <td>-0.036871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.654946</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.635102</td>\n",
       "      <td>-0.606817</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.064054</td>\n",
       "      <td>-1.008137</td>\n",
       "      <td>-0.933481</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.063679</td>\n",
       "      <td>1.079313</td>\n",
       "      <td>0.203930</td>\n",
       "      <td>0.104939</td>\n",
       "      <td>1.046611</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744579</th>\n",
       "      <td>0.226933</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>43240</td>\n",
       "      <td>0.133135</td>\n",
       "      <td>0.158188</td>\n",
       "      <td>445310</td>\n",
       "      <td>-0.058247</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.628851</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.608622</td>\n",
       "      <td>-0.609553</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.991151</td>\n",
       "      <td>-0.938082</td>\n",
       "      <td>-0.940463</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>1.031658</td>\n",
       "      <td>0.095556</td>\n",
       "      <td>0.132487</td>\n",
       "      <td>0.998473</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321200</th>\n",
       "      <td>0.252778</td>\n",
       "      <td>0.196143</td>\n",
       "      <td>21037</td>\n",
       "      <td>0.194430</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.110648</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>-0.611454</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.590969</td>\n",
       "      <td>-0.565780</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.945343</td>\n",
       "      <td>-0.893964</td>\n",
       "      <td>-0.834204</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>1.080727</td>\n",
       "      <td>0.195567</td>\n",
       "      <td>0.142737</td>\n",
       "      <td>1.044521</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74901</th>\n",
       "      <td>0.275938</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>90071</td>\n",
       "      <td>0.141177</td>\n",
       "      <td>0.178801</td>\n",
       "      <td>541310</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.251879</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>2.730474</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>0.556485</td>\n",
       "      <td>0.112702</td>\n",
       "      <td>1</td>\n",
       "      <td>1.316535</td>\n",
       "      <td>0.442430</td>\n",
       "      <td>0.106791</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>24.227422</td>\n",
       "      <td>0.064374</td>\n",
       "      <td>0.192698</td>\n",
       "      <td>4.937672</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426895</th>\n",
       "      <td>0.057056</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>95037</td>\n",
       "      <td>0.412096</td>\n",
       "      <td>0.380604</td>\n",
       "      <td>561720</td>\n",
       "      <td>-0.136849</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.041138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.524470</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.502703</td>\n",
       "      <td>-0.543894</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.743325</td>\n",
       "      <td>-0.698569</td>\n",
       "      <td>-0.785029</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.076491</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>0.251609</td>\n",
       "      <td>0.140635</td>\n",
       "      <td>0.924268</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192476</th>\n",
       "      <td>0.148611</td>\n",
       "      <td>0.197720</td>\n",
       "      <td>8882</td>\n",
       "      <td>0.194430</td>\n",
       "      <td>0.253203</td>\n",
       "      <td>238990</td>\n",
       "      <td>-0.045146</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>-0.031080</td>\n",
       "      <td>-0.011268</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.251879</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.635809</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.643928</td>\n",
       "      <td>-0.631440</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.010078</td>\n",
       "      <td>-1.032624</td>\n",
       "      <td>-0.998151</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.042348</td>\n",
       "      <td>1.006920</td>\n",
       "      <td>0.071497</td>\n",
       "      <td>0.067066</td>\n",
       "      <td>1.019778</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>0.097718</td>\n",
       "      <td>0.156276</td>\n",
       "      <td>39601</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.097535</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.123748</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>-0.524470</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.502703</td>\n",
       "      <td>-0.456348</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.743325</td>\n",
       "      <td>-0.698569</td>\n",
       "      <td>-0.609445</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>1.149277</td>\n",
       "      <td>0.271171</td>\n",
       "      <td>0.176966</td>\n",
       "      <td>1.101580</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28030</th>\n",
       "      <td>0.273994</td>\n",
       "      <td>0.239152</td>\n",
       "      <td>30307</td>\n",
       "      <td>0.269757</td>\n",
       "      <td>0.291471</td>\n",
       "      <td>541213</td>\n",
       "      <td>-0.045146</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.018263</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.110506</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.326172</td>\n",
       "      <td>-0.434461</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.117102</td>\n",
       "      <td>-0.394781</td>\n",
       "      <td>-0.569976</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.012462</td>\n",
       "      <td>0.254351</td>\n",
       "      <td>0.103913</td>\n",
       "      <td>0.028684</td>\n",
       "      <td>0.750751</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277869</th>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.222447</td>\n",
       "      <td>49418</td>\n",
       "      <td>0.246231</td>\n",
       "      <td>0.086229</td>\n",
       "      <td>541690</td>\n",
       "      <td>-0.097548</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>-0.018263</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.251879</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.524470</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.502703</td>\n",
       "      <td>-0.543894</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.743325</td>\n",
       "      <td>-0.698569</td>\n",
       "      <td>-0.785029</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.063668</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>0.179351</td>\n",
       "      <td>0.117060</td>\n",
       "      <td>0.924268</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773630</th>\n",
       "      <td>0.275938</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>90019</td>\n",
       "      <td>0.077741</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>448120</td>\n",
       "      <td>-0.097548</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.028337</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>1.342208</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>1.391478</td>\n",
       "      <td>1.272140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851094</td>\n",
       "      <td>0.871911</td>\n",
       "      <td>0.820722</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.063689</td>\n",
       "      <td>1.055079</td>\n",
       "      <td>-0.076680</td>\n",
       "      <td>-0.050065</td>\n",
       "      <td>1.093809</td>\n",
       "      <td>17.487834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560178 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            City     State    Zip      Bank  BankState   NAICS     NoEmp  \\\n",
       "148172  0.215946  0.165802  45648  0.740692   0.217642  452990 -0.123748   \n",
       "744579  0.226933  0.165802  43240  0.133135   0.158188  445310 -0.058247   \n",
       "321200  0.252778  0.196143  21037  0.194430   0.076619       0 -0.110648   \n",
       "74901   0.275938  0.184227  90071  0.141177   0.178801  541310  0.007255   \n",
       "426895  0.057056  0.184227  95037  0.412096   0.380604  561720 -0.136849   \n",
       "...          ...       ...    ...       ...        ...     ...       ...   \n",
       "192476  0.148611  0.197720   8882  0.194430   0.253203  238990 -0.045146   \n",
       "17730   0.097718  0.156276  39601  0.091954   0.097535       0 -0.123748   \n",
       "28030   0.273994  0.239152  30307  0.269757   0.291471  541213 -0.045146   \n",
       "277869  0.102190  0.222447  49418  0.246231   0.086229  541690 -0.097548   \n",
       "773630  0.275938  0.184227  90019  0.077741   0.217642  448120 -0.097548   \n",
       "\n",
       "        NewExist  CreateJob  RetainedJob  FranchiseCode  UrbanRural  \\\n",
       "148172  0.170670  -0.026808    -0.036871              0    0.186517   \n",
       "744579  0.170670  -0.035352    -0.045405              0    0.243731   \n",
       "321200  0.170670  -0.035352    -0.045405              1    0.070886   \n",
       "74901   0.170670   0.015917     0.005801              1    0.243731   \n",
       "426895  0.170670  -0.035352    -0.041138              0    0.243731   \n",
       "...          ...        ...          ...            ...         ...   \n",
       "192476  0.185603  -0.031080    -0.011268              1    0.243731   \n",
       "17730   0.185603  -0.035352    -0.045405              1    0.070886   \n",
       "28030   0.170670  -0.018263     0.005801              0    0.243731   \n",
       "277869  0.185603  -0.018263    -0.045405              1    0.243731   \n",
       "773630  0.170670  -0.035352    -0.028337              1    0.243731   \n",
       "\n",
       "        RevLineCr    LowDoc  DisbursementGross  BalanceGross    GrAppv  \\\n",
       "148172   0.152625  0.186815          -0.654946     -0.002095 -0.635102   \n",
       "744579   0.152625  0.186815          -0.628851     -0.002095 -0.608622   \n",
       "321200   0.152625  0.089154          -0.611454     -0.002095 -0.590969   \n",
       "74901    0.251879  0.186815           2.730474     -0.002095  0.556485   \n",
       "426895   0.152625  0.186815          -0.524470     -0.002095 -0.502703   \n",
       "...           ...       ...                ...           ...       ...   \n",
       "192476   0.251879  0.186815          -0.635809     -0.002095 -0.643928   \n",
       "17730    0.152625  0.089154          -0.524470     -0.002095 -0.502703   \n",
       "28030    0.152625  0.186815          -0.110506     -0.002095 -0.326172   \n",
       "277869   0.251879  0.186815          -0.524470     -0.002095 -0.502703   \n",
       "773630   0.152625  0.186815           1.342208     -0.002095  1.391478   \n",
       "\n",
       "        SBA_Appv  MIS_Status  Log_DisbursementGross  Log_GrAppv  Log_SBA_Appv  \\\n",
       "148172 -0.606817           1              -1.064054   -1.008137     -0.933481   \n",
       "744579 -0.609553           0              -0.991151   -0.938082     -0.940463   \n",
       "321200 -0.565780           0              -0.945343   -0.893964     -0.834204   \n",
       "74901   0.112702           1               1.316535    0.442430      0.106791   \n",
       "426895 -0.543894           0              -0.743325   -0.698569     -0.785029   \n",
       "...          ...         ...                    ...         ...           ...   \n",
       "192476 -0.631440           1              -1.010078   -1.032624     -0.998151   \n",
       "17730  -0.456348           0              -0.743325   -0.698569     -0.609445   \n",
       "28030  -0.434461           1              -0.117102   -0.394781     -0.569976   \n",
       "277869 -0.543894           0              -0.743325   -0.698569     -0.785029   \n",
       "773630  1.272140           0               0.851094    0.871911      0.820722   \n",
       "\n",
       "        Log_BalanceGross  TotalJobs  IncomeToLoanRatio  EmployeesToLoanRatio  \\\n",
       "148172         -0.002098  -0.063679           1.079313              0.203930   \n",
       "744579         -0.002098  -0.080758           1.031658              0.095556   \n",
       "321200         -0.002098  -0.080758           1.080727              0.195567   \n",
       "74901          -0.002098   0.021717          24.227422              0.064374   \n",
       "426895         -0.002098  -0.076491           0.964287              0.251609   \n",
       "...                  ...        ...                ...                   ...   \n",
       "192476         -0.002098  -0.042348           1.006920              0.071497   \n",
       "17730          -0.002098  -0.080758           1.149277              0.271171   \n",
       "28030          -0.002098  -0.012462           0.254351              0.103913   \n",
       "277869         -0.002098  -0.063668           0.964287              0.179351   \n",
       "773630         -0.002098  -0.063689           1.055079             -0.076680   \n",
       "\n",
       "        JobPerLoan  Gauren_SBA_Appv  DefaultRate  \n",
       "148172    0.104939         1.046611    17.487834  \n",
       "744579    0.132487         0.998473    17.487834  \n",
       "321200    0.142737         1.044521    17.487834  \n",
       "74901     0.192698         4.937672    17.487834  \n",
       "426895    0.140635         0.924268    17.487834  \n",
       "...            ...              ...          ...  \n",
       "192476    0.067066         1.019778    17.487834  \n",
       "17730     0.176966         1.101580    17.487834  \n",
       "28030     0.028684         0.750751    17.487834  \n",
       "277869    0.117060         0.924268    17.487834  \n",
       "773630   -0.050065         1.093809    17.487834  \n",
       "\n",
       "[560178 rows x 29 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>Log_DisbursementGross</th>\n",
       "      <th>Log_GrAppv</th>\n",
       "      <th>Log_SBA_Appv</th>\n",
       "      <th>Log_BalanceGross</th>\n",
       "      <th>TotalJobs</th>\n",
       "      <th>IncomeToLoanRatio</th>\n",
       "      <th>EmployeesToLoanRatio</th>\n",
       "      <th>JobPerLoan</th>\n",
       "      <th>Gauren_SBA_Appv</th>\n",
       "      <th>DefaultRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244526</th>\n",
       "      <td>0.169492</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>91360</td>\n",
       "      <td>0.141177</td>\n",
       "      <td>0.178801</td>\n",
       "      <td>621210</td>\n",
       "      <td>-0.045146</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>3.327185</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>3.405700</td>\n",
       "      <td>2.629607</td>\n",
       "      <td>0</td>\n",
       "      <td>1.464917</td>\n",
       "      <td>1.482899</td>\n",
       "      <td>1.289124</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>1.265278</td>\n",
       "      <td>-0.017168</td>\n",
       "      <td>-0.030711</td>\n",
       "      <td>1.295136</td>\n",
       "      <td>17.568114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473020</th>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>91326</td>\n",
       "      <td>0.154334</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>238990</td>\n",
       "      <td>-0.071347</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.019802</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.251879</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.559263</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.538010</td>\n",
       "      <td>-0.565780</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.819308</td>\n",
       "      <td>-0.772211</td>\n",
       "      <td>-0.834204</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.055155</td>\n",
       "      <td>0.988482</td>\n",
       "      <td>0.126104</td>\n",
       "      <td>0.097484</td>\n",
       "      <td>0.950917</td>\n",
       "      <td>17.568114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176231</th>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.198565</td>\n",
       "      <td>14203</td>\n",
       "      <td>0.073645</td>\n",
       "      <td>0.168202</td>\n",
       "      <td>541511</td>\n",
       "      <td>-0.123748</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>-0.026808</td>\n",
       "      <td>-0.036871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.251879</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.170323</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.502703</td>\n",
       "      <td>-0.543894</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.186719</td>\n",
       "      <td>-0.698569</td>\n",
       "      <td>-0.785029</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.063679</td>\n",
       "      <td>0.313155</td>\n",
       "      <td>0.227523</td>\n",
       "      <td>0.117079</td>\n",
       "      <td>0.924268</td>\n",
       "      <td>17.568114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605480</th>\n",
       "      <td>0.089294</td>\n",
       "      <td>0.176561</td>\n",
       "      <td>84066</td>\n",
       "      <td>0.186588</td>\n",
       "      <td>0.167275</td>\n",
       "      <td>532412</td>\n",
       "      <td>-0.136849</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.041138</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.200736</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>0.026891</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.224064</td>\n",
       "      <td>0.026535</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.076491</td>\n",
       "      <td>-61.401723</td>\n",
       "      <td>-41.859694</td>\n",
       "      <td>-23.397204</td>\n",
       "      <td>8.225365</td>\n",
       "      <td>17.568114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680297</th>\n",
       "      <td>0.174878</td>\n",
       "      <td>0.117244</td>\n",
       "      <td>55110</td>\n",
       "      <td>0.412096</td>\n",
       "      <td>0.380604</td>\n",
       "      <td>511120</td>\n",
       "      <td>-0.123748</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.026808</td>\n",
       "      <td>-0.036871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.646247</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.626275</td>\n",
       "      <td>-0.620496</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.039158</td>\n",
       "      <td>-0.984236</td>\n",
       "      <td>-0.968891</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.063679</td>\n",
       "      <td>1.041501</td>\n",
       "      <td>0.199434</td>\n",
       "      <td>0.102625</td>\n",
       "      <td>1.009313</td>\n",
       "      <td>17.568114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140684</th>\n",
       "      <td>0.221202</td>\n",
       "      <td>0.168644</td>\n",
       "      <td>72106</td>\n",
       "      <td>0.220430</td>\n",
       "      <td>0.130193</td>\n",
       "      <td>484121</td>\n",
       "      <td>-0.123748</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>-0.022535</td>\n",
       "      <td>-0.036871</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.472279</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.449744</td>\n",
       "      <td>-0.511064</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.639188</td>\n",
       "      <td>-0.597372</td>\n",
       "      <td>-0.715523</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.059406</td>\n",
       "      <td>0.924110</td>\n",
       "      <td>0.242139</td>\n",
       "      <td>0.116240</td>\n",
       "      <td>0.880015</td>\n",
       "      <td>17.568114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682787</th>\n",
       "      <td>0.412092</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>91306</td>\n",
       "      <td>0.545563</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>611519</td>\n",
       "      <td>-0.136849</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.041138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.663644</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.643928</td>\n",
       "      <td>-0.616119</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.089586</td>\n",
       "      <td>-1.032624</td>\n",
       "      <td>-0.957423</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.076491</td>\n",
       "      <td>1.077136</td>\n",
       "      <td>0.222114</td>\n",
       "      <td>0.124149</td>\n",
       "      <td>1.045136</td>\n",
       "      <td>17.568114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590016</th>\n",
       "      <td>0.153938</td>\n",
       "      <td>0.184227</td>\n",
       "      <td>92124</td>\n",
       "      <td>0.067005</td>\n",
       "      <td>0.217642</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085857</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>72590</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>-0.089549</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.061375</td>\n",
       "      <td>-0.078805</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.093816</td>\n",
       "      <td>-0.063339</td>\n",
       "      <td>-0.082084</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>1.136340</td>\n",
       "      <td>-1.089486</td>\n",
       "      <td>1.024779</td>\n",
       "      <td>0.778820</td>\n",
       "      <td>17.568114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687978</th>\n",
       "      <td>0.138222</td>\n",
       "      <td>0.188433</td>\n",
       "      <td>76834</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.139857</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.097548</td>\n",
       "      <td>0.170670</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>0.853358</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.810882</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616999</td>\n",
       "      <td>0.639443</td>\n",
       "      <td>0.593814</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>1.052383</td>\n",
       "      <td>-0.120298</td>\n",
       "      <td>-0.099593</td>\n",
       "      <td>1.104261</td>\n",
       "      <td>17.568114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158557</th>\n",
       "      <td>0.136499</td>\n",
       "      <td>0.143158</td>\n",
       "      <td>17112</td>\n",
       "      <td>0.081911</td>\n",
       "      <td>0.076427</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.123748</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>-0.035352</td>\n",
       "      <td>-0.045405</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>-0.587098</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.566255</td>\n",
       "      <td>-0.541267</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.884546</td>\n",
       "      <td>-0.835298</td>\n",
       "      <td>-0.779287</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.080758</td>\n",
       "      <td>1.084674</td>\n",
       "      <td>0.228627</td>\n",
       "      <td>0.149202</td>\n",
       "      <td>1.046165</td>\n",
       "      <td>17.568114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240077 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            City     State    Zip      Bank  BankState   NAICS     NoEmp  \\\n",
       "244526  0.169492  0.184227  91360  0.141177   0.178801  621210 -0.045146   \n",
       "473020  0.241379  0.184227  91326  0.154334   0.217642  238990 -0.071347   \n",
       "176231  0.141176  0.198565  14203  0.073645   0.168202  541511 -0.123748   \n",
       "605480  0.089294  0.176561  84066  0.186588   0.167275  532412 -0.136849   \n",
       "680297  0.174878  0.117244  55110  0.412096   0.380604  511120 -0.123748   \n",
       "...          ...       ...    ...       ...        ...     ...       ...   \n",
       "140684  0.221202  0.168644  72106  0.220430   0.130193  484121 -0.123748   \n",
       "682787  0.412092  0.184227  91306  0.545563   0.217642  611519 -0.136849   \n",
       "590016  0.153938  0.184227  92124  0.067005   0.217642       0  0.085857   \n",
       "687978  0.138222  0.188433  76834  0.103226   0.139857       0 -0.097548   \n",
       "158557  0.136499  0.143158  17112  0.081911   0.076427       0 -0.123748   \n",
       "\n",
       "        NewExist  CreateJob  RetainedJob  FranchiseCode  UrbanRural  \\\n",
       "244526  0.170670  -0.035352    -0.045405              1    0.070886   \n",
       "473020  0.170670  -0.035352    -0.019802              1    0.243731   \n",
       "176231  0.185603  -0.026808    -0.036871              0    0.243731   \n",
       "605480  0.170670  -0.035352    -0.041138              1    0.186517   \n",
       "680297  0.170670  -0.026808    -0.036871              0    0.243731   \n",
       "...          ...        ...          ...            ...         ...   \n",
       "140684  0.185603  -0.022535    -0.036871              1    0.186517   \n",
       "682787  0.185603  -0.035352    -0.041138              0    0.243731   \n",
       "590016  0.185603  -0.035352    -0.045405          72590    0.070886   \n",
       "687978  0.170670  -0.035352    -0.045405              1    0.070886   \n",
       "158557  0.185603  -0.035352    -0.045405              1    0.243731   \n",
       "\n",
       "        RevLineCr    LowDoc  DisbursementGross  BalanceGross    GrAppv  \\\n",
       "244526   0.152625  0.186815           3.327185     -0.002095  3.405700   \n",
       "473020   0.251879  0.186815          -0.559263     -0.002095 -0.538010   \n",
       "176231   0.251879  0.186815          -0.170323     -0.002095 -0.502703   \n",
       "605480   0.152625  0.186815          -0.200736     -0.002095  0.026891   \n",
       "680297   0.152625  0.186815          -0.646247     -0.002095 -0.626275   \n",
       "...           ...       ...                ...           ...       ...   \n",
       "140684   0.152625  0.186815          -0.472279     -0.002095 -0.449744   \n",
       "682787   0.152625  0.186815          -0.663644     -0.002095 -0.643928   \n",
       "590016   0.152625  0.186815          -0.089549     -0.002095 -0.061375   \n",
       "687978   0.152625  0.186815           0.853358     -0.002095  0.895425   \n",
       "158557   0.152625  0.089154          -0.587098     -0.002095 -0.566255   \n",
       "\n",
       "        SBA_Appv  MIS_Status  Log_DisbursementGross  Log_GrAppv  Log_SBA_Appv  \\\n",
       "244526  2.629607           0               1.464917    1.482899      1.289124   \n",
       "473020 -0.565780           0              -0.819308   -0.772211     -0.834204   \n",
       "176231 -0.543894           0              -0.186719   -0.698569     -0.785029   \n",
       "605480  0.003269           0              -0.224064    0.026535      0.003264   \n",
       "680297 -0.620496           1              -1.039158   -0.984236     -0.968891   \n",
       "...          ...         ...                    ...         ...           ...   \n",
       "140684 -0.511064           1              -0.639188   -0.597372     -0.715523   \n",
       "682787 -0.616119           1              -1.089586   -1.032624     -0.957423   \n",
       "590016 -0.078805           1              -0.093816   -0.063339     -0.082084   \n",
       "687978  0.810882           0               0.616999    0.639443      0.593814   \n",
       "158557 -0.541267           0              -0.884546   -0.835298     -0.779287   \n",
       "\n",
       "        Log_BalanceGross  TotalJobs  IncomeToLoanRatio  EmployeesToLoanRatio  \\\n",
       "244526         -0.002098  -0.080758           1.265278             -0.017168   \n",
       "473020         -0.002098  -0.055155           0.988482              0.126104   \n",
       "176231         -0.002098  -0.063679           0.313155              0.227523   \n",
       "605480         -0.002098  -0.076491         -61.401723            -41.859694   \n",
       "680297         -0.002098  -0.063679           1.041501              0.199434   \n",
       "...                  ...        ...                ...                   ...   \n",
       "140684         -0.002098  -0.059406           0.924110              0.242139   \n",
       "682787         -0.002098  -0.076491           1.077136              0.222114   \n",
       "590016         -0.002098  -0.080758           1.136340             -1.089486   \n",
       "687978         -0.002098  -0.080758           1.052383             -0.120298   \n",
       "158557         -0.002098  -0.080758           1.084674              0.228627   \n",
       "\n",
       "        JobPerLoan  Gauren_SBA_Appv  DefaultRate  \n",
       "244526   -0.030711         1.295136    17.568114  \n",
       "473020    0.097484         0.950917    17.568114  \n",
       "176231    0.117079         0.924268    17.568114  \n",
       "605480  -23.397204         8.225365    17.568114  \n",
       "680297    0.102625         1.009313    17.568114  \n",
       "...            ...              ...          ...  \n",
       "140684    0.116240         0.880015    17.568114  \n",
       "682787    0.124149         1.045136    17.568114  \n",
       "590016    1.024779         0.778820    17.568114  \n",
       "687978   -0.099593         1.104261    17.568114  \n",
       "158557    0.149202         1.046165    17.568114  \n",
       "\n",
       "[240077 rows x 29 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_encoded.copy()\n",
    "X_test = test_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'MIS_Status'\n",
    "y_train = X_train['MIS_Status']\n",
    "X_train.drop(columns=[target_col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'MIS_Status'\n",
    "y_test = X_test['MIS_Status']\n",
    "X_test.drop(columns=[target_col], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_data = lgb.Dataset(data=X_train, label=y_train, params={\"verbose\":-1})\n",
    "test_data = lgb.Dataset(data=X_test, label=y_test, params={\"verbose\":-1})\n",
    "lgb_clf = lgb.train(params={\"verbose\":-1},\n",
    "                    train_set=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on Test dataset: 0.8205511277259651\n",
      "AUC score on Train dataset: 0.8468756526040521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"AUC score on Test dataset:\", roc_auc_score(y_test, lgb_clf.predict(X_test)))\n",
    "print(\"AUC score on Train dataset:\", roc_auc_score(y_train, lgb_clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import LightGBMPruningCallback\n",
    "import tqdm as notebook_tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "study_model_iteractions = {}\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        #         \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"metric\":\"auc\"\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    cv_iteractions = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(data=X_train, label=y_train, params={\"verbose\":-1}, categorical_feature=categorical_columns)\n",
    "        valid_data = lgb.Dataset(data=X_valid, label=y_valid, params={\"verbose\":-1}, categorical_feature=categorical_columns)\n",
    "        lgb_clf = lgb.train(params=param_grid,\n",
    "                            train_set=train_data,\n",
    "                            valid_sets=[valid_data],\n",
    "                            categorical_feature=categorical_columns,\n",
    "                            callbacks=[LightGBMPruningCallback(trial, \"auc\"),\n",
    "                                        lgb.early_stopping(stopping_rounds=5)]  \n",
    "                            )\n",
    "        preds = lgb_clf.predict(X_valid)\n",
    "        cv_scores[idx] = roc_auc_score(y_valid, preds)\n",
    "        cv_iteractions[idx] = lgb_clf.best_iteration\n",
    "    \n",
    "    study_model_iteractions[trial.number] = np.mean(cv_iteractions)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import LightGBMPruningCallback\n",
    "import tqdm as notebook_tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "study_model_iteractions = {}\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        # Refer to the Official guide : https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "        \"num_iterations\": 10000,\n",
    "        \"num_threads\": 16,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, step=0.05),\n",
    "        #\"num_leaves\": trial.suggest_int(\"num_leaves\", 50, 150, step=5),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        #\"max_depth\": trial.suggest_int(\"max_depth\", 5, 20, step=2),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 100, 1000, step=100),\n",
    "        ##############################\n",
    "        #'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        #'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        #\"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.01, 0.1, step=0.01),\n",
    "        #\"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.01, 0.1, step=0.01),\n",
    "        ########################\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.8, 1.0, step=0.1),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [5]),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.8, 1.0, step=0.1),\n",
    "        #######################\n",
    "        \"is_unbalance\": trial.suggest_categorical(\"is_unbalance\",[True, False]),\n",
    "        ########################\n",
    "        \"verbose\": -1,\n",
    "        \"objective\":\"binary\",\n",
    "        \"metric\":\"auc\"\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    cv_iteractions = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(data=X_train, label=y_train, params={\"verbose\":-1}, categorical_feature=categorical_columns)\n",
    "        valid_data = lgb.Dataset(data=X_valid, label=y_valid, params={\"verbose\":-1}, categorical_feature=categorical_columns)\n",
    "        lgb_clf = lgb.train(params=param_grid,\n",
    "                            train_set=train_data,\n",
    "                            valid_sets=[valid_data],\n",
    "                            categorical_feature=categorical_columns,\n",
    "                            callbacks=[LightGBMPruningCallback(trial, \"auc\"),\n",
    "                                        lgb.early_stopping(stopping_rounds=5)]  \n",
    "                            )\n",
    "        preds = lgb_clf.predict(X_valid)\n",
    "        cv_scores[idx] = roc_auc_score(y_valid, preds)\n",
    "        cv_iteractions[idx] = lgb_clf.best_iteration\n",
    "    \n",
    "    study_model_iteractions[trial.number] = np.mean(cv_iteractions)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 13:48:16,780] A new study created in memory with name: LGBM Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.801413\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.800578\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.802428\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's auc: 0.80037\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's auc: 0.801783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 13:48:37,701] Trial 0 finished with value: 0.801314474180532 and parameters: {'learning_rate': 0.26, 'num_leaves': 380, 'max_depth': 11, 'min_data_in_leaf': 200, 'lambda_l1': 25, 'lambda_l2': 75, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': False}. Best is trial 0 with value: 0.801314474180532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[647]\tvalid_0's auc: 0.799683\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[587]\tvalid_0's auc: 0.79893\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's auc: 0.797246\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[634]\tvalid_0's auc: 0.798788\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[485]\tvalid_0's auc: 0.799062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 13:49:20,974] Trial 1 finished with value: 0.7987416761387767 and parameters: {'learning_rate': 0.26, 'num_leaves': 760, 'max_depth': 3, 'min_data_in_leaf': 600, 'lambda_l1': 20, 'lambda_l2': 15, 'bagging_fraction': 0.9, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': False}. Best is trial 0 with value: 0.801314474180532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's auc: 0.799028\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.798746\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-12-08 13:49:30,152] Trial 2 failed with parameters: {'learning_rate': 0.26, 'num_leaves': 1220, 'max_depth': 9, 'min_data_in_leaf': 600, 'lambda_l1': 65, 'lambda_l2': 5, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'feature_fraction': 1.0, 'is_unbalance': False} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Work\\Gre\\UTD\\Courses\\Fall\\MIS6341\\Softwares\\Python\\ml-fall-2023\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_25088\\2029209496.py\", line 2, in <lambda>\n",
      "    func = lambda trial: objective(trial, X_train, y_train)\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_25088\\3360629302.py\", line 51, in objective\n",
      "    lgb_clf = lgb.train(params=param_grid,\n",
      "  File \"d:\\Work\\Gre\\UTD\\Courses\\Fall\\MIS6341\\Softwares\\Python\\ml-fall-2023\\lib\\site-packages\\lightgbm\\engine.py\", line 266, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"d:\\Work\\Gre\\UTD\\Courses\\Fall\\MIS6341\\Softwares\\Python\\ml-fall-2023\\lib\\site-packages\\lightgbm\\basic.py\", line 3557, in update\n",
      "    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2023-12-08 13:49:30,155] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBM Classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, X_train, y_train)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Work\\Gre\\UTD\\Courses\\Fall\\MIS6341\\Softwares\\Python\\ml-fall-2023\\lib\\site-packages\\optuna\\study\\study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Work\\Gre\\UTD\\Courses\\Fall\\MIS6341\\Softwares\\Python\\ml-fall-2023\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\Work\\Gre\\UTD\\Courses\\Fall\\MIS6341\\Softwares\\Python\\ml-fall-2023\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32md:\\Work\\Gre\\UTD\\Courses\\Fall\\MIS6341\\Softwares\\Python\\ml-fall-2023\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32md:\\Work\\Gre\\UTD\\Courses\\Fall\\MIS6341\\Softwares\\Python\\ml-fall-2023\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[99], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBM Classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(func, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[1;32mIn[98], line 51\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial, X, y)\u001b[0m\n\u001b[0;32m     49\u001b[0m train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(data\u001b[38;5;241m=\u001b[39mX_train, label\u001b[38;5;241m=\u001b[39my_train, params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m}, categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_columns)\n\u001b[0;32m     50\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(data\u001b[38;5;241m=\u001b[39mX_valid, label\u001b[38;5;241m=\u001b[39my_valid, params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m}, categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_columns)\n\u001b[1;32m---> 51\u001b[0m lgb_clf \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mLightGBMPruningCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m preds \u001b[38;5;241m=\u001b[39m lgb_clf\u001b[38;5;241m.\u001b[39mpredict(X_valid)\n\u001b[0;32m     59\u001b[0m cv_scores[idx] \u001b[38;5;241m=\u001b[39m roc_auc_score(y_valid, preds)\n",
      "File \u001b[1;32md:\\Work\\Gre\\UTD\\Courses\\Fall\\MIS6341\\Softwares\\Python\\ml-fall-2023\\lib\\site-packages\\lightgbm\\engine.py:266\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    259\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m    260\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    261\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[0;32m    262\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[0;32m    263\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[0;32m    264\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 266\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\Gre\\UTD\\Courses\\Fall\\MIS6341\\Softwares\\Python\\ml-fall-2023\\lib\\site-packages\\lightgbm\\basic.py:3557\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 3557\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3558\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Classifier\")\n",
    "func = lambda trial: objective(trial, X_train, y_train)\n",
    "study.optimize(func, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (AUC): 0.75404\n",
      "\tBest params:\n",
      "\t\tlearning_rate: 0.16000000000000003\n",
      "\t\tnum_leaves: 2320\n",
      "\t\tmax_depth: 4\n",
      "\t\tmin_data_in_leaf: 100\n",
      "\t\tlambda_l1: 5\n",
      "\t\tlambda_l2: 50\n",
      "\t\tbagging_fraction: 0.8\n",
      "\t\tbagging_freq: 5\n",
      "\t\tfeature_fraction: 0.8\n",
      "\t\tis_unbalance: True\n",
      "Best model best_iteration: 22.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\tBest value (AUC): {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")\n",
    "\n",
    "print(\"Best model best_iteration:\", study_model_iteractions[study.best_trial.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': -1, 'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.16000000000000003, 'num_leaves': 2320, 'max_depth': 4, 'min_data_in_leaf': 100, 'lambda_l1': 5, 'lambda_l2': 50, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 0.8, 'is_unbalance': True, 'num_iterations': 22}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\"verbose\": -1,\n",
    "                \"objective\":\"binary\",\n",
    "                \"metric\":\"auc\"\n",
    "            }\n",
    "for key,val in study.best_params.items():\n",
    "    best_params[key] = val\n",
    "\n",
    "best_params[\"num_iterations\"] = int(study_model_iteractions[study.best_trial.number])\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with parameters found using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = lgb.Dataset(data=X_train, label=y_train, params={\"verbose\":-1})\n",
    "test_data = lgb.Dataset(data=X_test, label=y_test, params={\"verbose\":-1})\n",
    "best_lgb = lgb.train(params=best_params,\n",
    "                    train_set=train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on Test dataset: 0.7941855023542295\n",
      "AUC score on Train dataset: 0.8168939523486363\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC score on Test dataset:\", roc_auc_score(y_test, best_lgb.predict(X_test)))\n",
    "print(\"AUC score on Train dataset:\", roc_auc_score(y_train, best_lgb.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna LightGBM Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.integration.lightgbm as lgb_optuna\n",
    "\n",
    "train_data = lgb_optuna.Dataset(data=X_train, label=y_train, params={\"verbose\":-1})\n",
    "test_data = lgb_optuna.Dataset(data=X_test, label=y_test, params={\"verbose\":-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 13:09:25,895] A new study created in memory with name: no-name-408e7fdb-ff88-47cc-9837-a251230c035a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:09:30,809] Trial 0 finished with value: 0.8213857348065972 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.8213857348065972.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.821386\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820974\n",
      "[200]\tvalid_0's auc: 0.825087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:09:40,557] Trial 1 finished with value: 0.8274361264266092 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.8274361264266092.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's auc: 0.827436\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:09:41,795] Trial 2 finished with value: 0.7995953511467344 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.8274361264266092.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.799595\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.821073\n",
      "[200]\tvalid_0's auc: 0.825099\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's auc: 0.825179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:09:49,041] Trial 3 finished with value: 0.8251794860809585 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.8274361264266092.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:09:50,266] Trial 4 finished with value: 0.7997713717796255 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.8274361264266092.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.799771\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.821081\n",
      "[200]\tvalid_0's auc: 0.825072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:09:58,615] Trial 5 finished with value: 0.8259575658217385 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.8274361264266092.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's auc: 0.825958\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:02,873] Trial 6 finished with value: 0.8210950776356571 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.8274361264266092.\n",
      "feature_fraction, val_score: 0.827436: 100%|##########| 7/7 [00:36<00:00,  5.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.821001\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.821095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:07,836] Trial 7 finished with value: 0.826154516021373 and parameters: {'num_leaves': 2419}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826155\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.827436:   5%|5         | 1/20 [00:10<01:33,  4.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:13,626] Trial 8 finished with value: 0.826154516021373 and parameters: {'num_leaves': 3576}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:18,688] Trial 9 finished with value: 0.8260331580080544 and parameters: {'num_leaves': 1749}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826033\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:19,819] Trial 10 finished with value: 0.7532242311729355 and parameters: {'num_leaves': 2}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.753224\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:25,365] Trial 11 finished with value: 0.826154516021373 and parameters: {'num_leaves': 2747}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826155\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:30,110] Trial 12 finished with value: 0.8260584459368836 and parameters: {'num_leaves': 1579}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826058\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-08 13:10:35,747] Trial 13 finished with value: 0.826154516021373 and parameters: {'num_leaves': 3935}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:38,990] Trial 14 finished with value: 0.8245861846708887 and parameters: {'num_leaves': 751}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.824586\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:44,359] Trial 15 finished with value: 0.826154516021373 and parameters: {'num_leaves': 2739}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826155\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:49,090] Trial 16 finished with value: 0.826154516021373 and parameters: {'num_leaves': 2730}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826155\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:53,028] Trial 17 finished with value: 0.8259005730356284 and parameters: {'num_leaves': 1039}. Best is trial 7 with value: 0.826154516021373.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.825901\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:10:58,305] Trial 18 finished with value: 0.8261577786978079 and parameters: {'num_leaves': 2244}. Best is trial 18 with value: 0.8261577786978079.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826158\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:11:03,612] Trial 19 finished with value: 0.826154516021373 and parameters: {'num_leaves': 3417}. Best is trial 18 with value: 0.8261577786978079.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826155\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:11:08,687] Trial 20 finished with value: 0.826122695671121 and parameters: {'num_leaves': 2059}. Best is trial 18 with value: 0.8261577786978079.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:11:13,916] Trial 21 finished with value: 0.8261415121597745 and parameters: {'num_leaves': 2288}. Best is trial 18 with value: 0.8261577786978079.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826142\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:11:17,734] Trial 22 finished with value: 0.8261478213227412 and parameters: {'num_leaves': 1158}. Best is trial 18 with value: 0.8261577786978079.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826148\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:11:24,029] Trial 23 finished with value: 0.826154516021373 and parameters: {'num_leaves': 2369}. Best is trial 18 with value: 0.8261577786978079.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826155\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:11:31,099] Trial 24 finished with value: 0.826154516021373 and parameters: {'num_leaves': 3218}. Best is trial 18 with value: 0.8261577786978079.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:11:36,228] Trial 25 finished with value: 0.8261290547931841 and parameters: {'num_leaves': 1497}. Best is trial 18 with value: 0.8261577786978079.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:11:41,812] Trial 26 finished with value: 0.826154516021373 and parameters: {'num_leaves': 2900}. Best is trial 18 with value: 0.8261577786978079.\n",
      "num_leaves, val_score: 0.827436: 100%|##########| 20/20 [01:38<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.826155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820875\n",
      "[200]\tvalid_0's auc: 0.824943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:11:51,784] Trial 27 finished with value: 0.826956385996343 and parameters: {'bagging_fraction': 0.70482021406053, 'bagging_freq': 3}. Best is trial 27 with value: 0.826956385996343.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's auc: 0.826956\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820218\n",
      "[200]\tvalid_0's auc: 0.825129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:12:01,300] Trial 28 finished with value: 0.8257818768118185 and parameters: {'bagging_fraction': 0.7228587255123846, 'bagging_freq': 3}. Best is trial 27 with value: 0.826956385996343.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's auc: 0.825782\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.819439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:12:08,877] Trial 29 finished with value: 0.8233527448983227 and parameters: {'bagging_fraction': 0.4898071500761211, 'bagging_freq': 2}. Best is trial 27 with value: 0.826956385996343.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's auc: 0.823353\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:12:16,679] Trial 30 finished with value: 0.8236275070495939 and parameters: {'bagging_fraction': 0.9553434358737323, 'bagging_freq': 7}. Best is trial 27 with value: 0.826956385996343.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.823628\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:12:24,084] Trial 31 finished with value: 0.8229729314067716 and parameters: {'bagging_fraction': 0.6821013950473284, 'bagging_freq': 5}. Best is trial 27 with value: 0.826956385996343.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's auc: 0.822973\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:12:32,401] Trial 32 finished with value: 0.8237445884085096 and parameters: {'bagging_fraction': 0.6998539549141892, 'bagging_freq': 1}. Best is trial 27 with value: 0.826956385996343.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's auc: 0.823745\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.819528\n",
      "[200]\tvalid_0's auc: 0.824228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:12:43,756] Trial 33 finished with value: 0.82537301294433 and parameters: {'bagging_fraction': 0.43368617708217166, 'bagging_freq': 5}. Best is trial 27 with value: 0.826956385996343.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's auc: 0.825373\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:12:53,048] Trial 34 finished with value: 0.8246126889899005 and parameters: {'bagging_fraction': 0.9150523776507908, 'bagging_freq': 4}. Best is trial 27 with value: 0.826956385996343.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.824613\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:13:01,498] Trial 35 finished with value: 0.8235324407595638 and parameters: {'bagging_fraction': 0.8170913743603612, 'bagging_freq': 7}. Best is trial 27 with value: 0.826956385996343.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's auc: 0.823532\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:13:15,460] Trial 36 finished with value: 0.8277031534241576 and parameters: {'bagging_fraction': 0.5638971041664391, 'bagging_freq': 1}. Best is trial 36 with value: 0.8277031534241576.\n",
      "bagging, val_score: 0.827703: 100%|##########| 10/10 [01:33<00:00,  9.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:13:30,350] Trial 37 finished with value: 0.8277031534241576 and parameters: {'feature_fraction': 0.516}. Best is trial 37 with value: 0.8277031534241576.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820209\n",
      "[200]\tvalid_0's auc: 0.824595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:13:40,293] Trial 38 finished with value: 0.8250771914165288 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 37 with value: 0.8277031534241576.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's auc: 0.825077\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:13:47,982] Trial 39 finished with value: 0.8242539407453727 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 37 with value: 0.8277031534241576.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's auc: 0.824254\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820617\n",
      "[200]\tvalid_0's auc: 0.82471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:13:59,031] Trial 40 finished with value: 0.8262509119781463 and parameters: {'feature_fraction': 0.58}. Best is trial 37 with value: 0.8277031534241576.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's auc: 0.826251\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:14:13,622] Trial 41 finished with value: 0.8277031534241576 and parameters: {'feature_fraction': 0.484}. Best is trial 37 with value: 0.8277031534241576.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.821113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:14:19,505] Trial 42 finished with value: 0.8230762850363174 and parameters: {'feature_fraction': 0.42}. Best is trial 37 with value: 0.8277031534241576.\n",
      "feature_fraction_stage2, val_score: 0.827703: 100%|##########| 6/6 [01:04<00:00, 10.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's auc: 0.823076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:14:28,880] Trial 43 finished with value: 0.8258954615132074 and parameters: {'lambda_l1': 0.00043836656325946103, 'lambda_l2': 0.00047688564686361603}. Best is trial 43 with value: 0.8258954615132074.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's auc: 0.825895\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820259\n",
      "[200]\tvalid_0's auc: 0.825007\n",
      "[300]\tvalid_0's auc: 0.827409\n",
      "[400]\tvalid_0's auc: 0.828675\n",
      "[500]\tvalid_0's auc: 0.829888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:14:48,038] Trial 44 finished with value: 0.8299583107514025 and parameters: {'lambda_l1': 1.1298901291575557e-08, 'lambda_l2': 8.587835379337236}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[502]\tvalid_0's auc: 0.829958\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820679\n",
      "[200]\tvalid_0's auc: 0.82491\n",
      "[300]\tvalid_0's auc: 0.827209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:15:01,199] Trial 45 finished with value: 0.8273377798486642 and parameters: {'lambda_l1': 3.67767695921121e-08, 'lambda_l2': 7.523465984341601}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[304]\tvalid_0's auc: 0.827338\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820826\n",
      "[200]\tvalid_0's auc: 0.825224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:15:13,248] Trial 46 finished with value: 0.8271408052685114 and parameters: {'lambda_l1': 1.1308798638098176e-08, 'lambda_l2': 4.713138355418288}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[287]\tvalid_0's auc: 0.827141\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820807\n",
      "[200]\tvalid_0's auc: 0.825599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:15:23,679] Trial 47 finished with value: 0.826543179700965 and parameters: {'lambda_l1': 7.855601210349932, 'lambda_l2': 5.1461856809573095e-08}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's auc: 0.826543\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:15:34,316] Trial 48 finished with value: 0.8258952023728582 and parameters: {'lambda_l1': 4.621555853614326e-06, 'lambda_l2': 0.0230350262970697}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's auc: 0.825895\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:15:44,085] Trial 49 finished with value: 0.8258952048887839 and parameters: {'lambda_l1': 1.9717376551170918e-05, 'lambda_l2': 0.022680695625209}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's auc: 0.825895\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:15:58,219] Trial 50 finished with value: 0.8277031535439635 and parameters: {'lambda_l1': 1.1288974193004864e-08, 'lambda_l2': 9.111665229611795e-07}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:16:11,563] Trial 51 finished with value: 0.8277031534241576 and parameters: {'lambda_l1': 1.519436282003942e-08, 'lambda_l2': 4.484706134417923e-07}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:16:23,979] Trial 52 finished with value: 0.8277031534241576 and parameters: {'lambda_l1': 1.0637323686945633e-08, 'lambda_l2': 5.004985180648629e-07}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:16:36,072] Trial 53 finished with value: 0.8277031529449336 and parameters: {'lambda_l1': 1.6061545353426933e-07, 'lambda_l2': 1.8037597327713072e-06}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:16:48,443] Trial 54 finished with value: 0.8277031528251276 and parameters: {'lambda_l1': 3.65027529352504e-07, 'lambda_l2': 3.2813787636570894e-06}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:17:02,119] Trial 55 finished with value: 0.8277031534241576 and parameters: {'lambda_l1': 1.4979168706790313e-08, 'lambda_l2': 1.1491821703096699e-08}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:17:15,930] Trial 56 finished with value: 0.8277031537835755 and parameters: {'lambda_l1': 4.827199242139198e-07, 'lambda_l2': 3.5890347643707147e-05}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:17:28,124] Trial 57 finished with value: 0.8277031541429934 and parameters: {'lambda_l1': 6.806241654915263e-07, 'lambda_l2': 3.836429425552569e-05}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:17:41,353] Trial 58 finished with value: 0.8277031528251276 and parameters: {'lambda_l1': 6.787429668677014e-07, 'lambda_l2': 0.00011379339169931773}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:17:54,071] Trial 59 finished with value: 0.8277031540231875 and parameters: {'lambda_l1': 3.250226709354578e-07, 'lambda_l2': 3.418840975515011e-05}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:18:07,013] Trial 60 finished with value: 0.8277031535439635 and parameters: {'lambda_l1': 2.981061723418087e-07, 'lambda_l2': 2.8291012153047283e-05}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:18:19,370] Trial 61 finished with value: 0.8277031522260977 and parameters: {'lambda_l1': 4.851677275919252e-07, 'lambda_l2': 1.6427007766731608e-05}. Best is trial 44 with value: 0.8299583107514025.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.82101\n",
      "[200]\tvalid_0's auc: 0.824619\n",
      "[300]\tvalid_0's auc: 0.827185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:18:32,543] Trial 62 finished with value: 0.8277031530647396 and parameters: {'lambda_l1': 1.57808497162591e-07, 'lambda_l2': 2.6237773170124403e-05}. Best is trial 44 with value: 0.8299583107514025.\n",
      "regularization_factors, val_score: 0.829958: 100%|##########| 20/20 [04:13<00:00, 12.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820695\n",
      "[200]\tvalid_0's auc: 0.82511\n",
      "[300]\tvalid_0's auc: 0.827392\n",
      "[400]\tvalid_0's auc: 0.828844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:18:50,545] Trial 63 finished with value: 0.8298394370350233 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.8298394370350233.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's auc: 0.829839\n",
      "Early stopping, best iteration is:\n",
      "[495]\tvalid_0's auc: 0.829839\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820232\n",
      "[200]\tvalid_0's auc: 0.824652\n",
      "[300]\tvalid_0's auc: 0.827378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:19:03,291] Trial 64 finished with value: 0.8283711866338499 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.8298394370350233.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's auc: 0.828371\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820917\n",
      "[200]\tvalid_0's auc: 0.825138\n",
      "[300]\tvalid_0's auc: 0.82743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:19:15,469] Trial 65 finished with value: 0.8279734622071955 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.8298394370350233.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's auc: 0.827973\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.820253\n",
      "[200]\tvalid_0's auc: 0.824652\n",
      "[300]\tvalid_0's auc: 0.826997\n",
      "[400]\tvalid_0's auc: 0.828138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:19:31,634] Trial 66 finished with value: 0.8290972687194248 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.8298394370350233.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[484]\tvalid_0's auc: 0.829097\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4737\n",
      "[LightGBM] [Info] Number of data points in the train set: 560178, number of used features: 28\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[100]\tvalid_0's auc: 0.821478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A[I 2023-12-08 13:19:36,349] Trial 67 finished with value: 0.8217209293139527 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.8298394370350233.\n",
      "min_data_in_leaf, val_score: 0.829958: 100%|##########| 5/5 [01:03<00:00, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.821721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import early_stopping\n",
    "from lightgbm import log_evaluation\n",
    "\n",
    "params = {\n",
    "        #         \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": 1000,\n",
    "        #\"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        #\"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": 12,\n",
    "        #\"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        #\"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "        #\"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        #\"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        #\"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        #\"bagging_fraction\": trial.suggest_float(\n",
    "         #   \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        #),\n",
    "        #\"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        #\"feature_fraction\": trial.suggest_float(\n",
    "         #   \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        #),\n",
    "        \"metric\":\"auc\"\n",
    "    }\n",
    "\n",
    "\n",
    "model = lgb_optuna.train(params,\n",
    "                        train_data,\n",
    "                        valid_sets=[test_data],\n",
    "                        callbacks=[early_stopping(stopping_rounds=5), log_evaluation(100)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score on Test dataset: 0.8299583107514024\n",
      "  Best Model Params: \n",
      "    max_depth: 12\n",
      "    metric: auc\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 1.1298901291575557e-08\n",
      "    lambda_l2: 8.587835379337236\n",
      "    num_leaves: 31\n",
      "    feature_fraction: 0.5\n",
      "    bagging_fraction: 0.5638971041664391\n",
      "    bagging_freq: 1\n",
      "    min_child_samples: 20\n",
      "    objective: None\n",
      "    num_iterations: 1000\n",
      "Model Best Iteration: 502\n"
     ]
    }
   ],
   "source": [
    "best_params = model.params\n",
    "print(\"AUC score on Test dataset:\", roc_auc_score(y_test, model.predict(X_test, num_iteration=model.best_iteration)))\n",
    "print(\"  Best Model Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "print(\"Model Best Iteration:\", model.best_iteration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-fall-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
